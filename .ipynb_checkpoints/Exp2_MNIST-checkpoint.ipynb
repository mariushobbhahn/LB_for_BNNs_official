{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi\n",
    "#using a GeForce GTX1080 Ti for reproducibility for all timing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from utils.LB_utils import * \n",
    "from utils.load_not_MNIST import notMNIST\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from laplace import Laplace\n",
    "import utils.scoring as scoring\n",
    "\n",
    "s = 1\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "cuda status:  True\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cuda_status = torch.cuda.is_available()\n",
    "print(\"device: \", device)\n",
    "print(\"cuda status: \", cuda_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define network\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, 5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2,2),\n",
    "            torch.nn.Conv2d(16, 32, 5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2,2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(4 * 4 * 32, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN_MNIST = 128\n",
    "BATCH_SIZE_TEST_MNIST = 128\n",
    "MAX_ITER_MNIST = 6\n",
    "LR_TRAIN_MNIST = 10e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "MNIST_train = torchvision.datasets.MNIST(\n",
    "        '~/data/mnist',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=MNIST_transform)\n",
    "\n",
    "MNIST_train_loader = torch.utils.data.dataloader.DataLoader(\n",
    "    MNIST_train,\n",
    "    batch_size=BATCH_SIZE_TRAIN_MNIST,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "MNIST_test = torchvision.datasets.MNIST(\n",
    "        '~/data/mnist',\n",
    "        train=False,\n",
    "        download=False,\n",
    "        transform=MNIST_transform)\n",
    "\n",
    "MNIST_test_loader = torch.utils.data.dataloader.DataLoader(\n",
    "    MNIST_test,\n",
    "    batch_size=BATCH_SIZE_TEST_MNIST,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = ConvNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "mnist_train_optimizer = torch.optim.Adam(mnist_model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "MNIST_PATH = \"pretrained_weights/MNIST_pretrained_10_classes_last_layer_s{}.pth\".format(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training routine\n",
    "\n",
    "def train(model, train_loader, optimizer, max_iter, path, verbose=True):\n",
    "    max_len = len(train_loader)\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "            \n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            output = model(x)\n",
    "\n",
    "            accuracy = get_accuracy(output, y)\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if verbose and batch_idx % 50 == 0:\n",
    "                print(\n",
    "                    \"Iteration {}; {}/{} \\t\".format(iter, batch_idx, max_len) +\n",
    "                    \"Minibatch Loss %.3f  \" % (loss) +\n",
    "                    \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "                )\n",
    "\n",
    "    print(\"saving model at: {}\".format(path))\n",
    "    torch.save(mnist_model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(mnist_model, MNIST_train_loader, mnist_train_optimizer, MAX_ITER_MNIST, MNIST_PATH, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: pretrained_weights/MNIST_pretrained_10_classes_last_layer_s1.pth\n",
      "Batch 0/79 \tAccuracy 100%\n",
      "Batch 10/79 \tAccuracy 96%\n",
      "Batch 20/79 \tAccuracy 98%\n",
      "Batch 30/79 \tAccuracy 98%\n",
      "Batch 40/79 \tAccuracy 100%\n",
      "Batch 50/79 \tAccuracy 99%\n",
      "Batch 60/79 \tAccuracy 100%\n",
      "Batch 70/79 \tAccuracy 98%\n",
      "overall test accuracy on MNIST: 98.84 %\n"
     ]
    }
   ],
   "source": [
    "#predict in distribution\n",
    "MNIST_PATH = \"pretrained_weights/MNIST_pretrained_10_classes_last_layer_s{}.pth\".format(s)\n",
    "#MNIST_PATH = \"pretrained_weights/MNIST_pretrained_10_classes_last_layer.pth\"\n",
    "\n",
    "mnist_model = ConvNet().to(device)\n",
    "print(\"loading model from: {}\".format(MNIST_PATH))\n",
    "mnist_model.load_state_dict(torch.load(MNIST_PATH))\n",
    "mnist_model.eval()\n",
    "\n",
    "acc = []\n",
    "\n",
    "max_len = len(MNIST_test_loader)\n",
    "for batch_idx, (x, y) in enumerate(MNIST_test_loader):\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    output = mnist_model(x)\n",
    "\n",
    "    accuracy = get_accuracy(output, y)\n",
    "    if batch_idx % 10 == 0:\n",
    "        print(\n",
    "            \"Batch {}/{} \\t\".format(batch_idx, max_len) + \n",
    "            \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "        )\n",
    "    acc.append(accuracy)\n",
    "\n",
    "avg_acc = np.mean(acc)\n",
    "print('overall test accuracy on MNIST: {:.02f} %'.format(avg_acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TEST_FMNIST = 128\n",
    "BATCH_SIZE_TEST_KMNIST = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FMNIST_test = torchvision.datasets.FashionMNIST(\n",
    "        '~/data/fmnist', train=False, download=True,\n",
    "        transform=MNIST_transform)   #torchvision.transforms.ToTensor())\n",
    "\n",
    "FMNIST_test_loader = torch.utils.data.DataLoader(\n",
    "    FMNIST_test,\n",
    "    batch_size=BATCH_SIZE_TEST_FMNIST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMNIST_test = torchvision.datasets.KMNIST(\n",
    "        '~/data/kmnist', train=False, download=True,\n",
    "        transform=MNIST_transform)\n",
    "\n",
    "KMNIST_test_loader = torch.utils.data.DataLoader(\n",
    "    KMNIST_test,\n",
    "    batch_size=BATCH_SIZE_TEST_KMNIST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png is broken\n",
      "File A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png is broken\n"
     ]
    }
   ],
   "source": [
    "#root = os.path.abspath('~/data')\n",
    "root = os.path.expanduser('~/data')\n",
    "\n",
    "# Instantiating the notMNIST dataset class we created\n",
    "notMNIST_test = notMNIST(root=os.path.join(root, 'notMNIST_small'),\n",
    "                               transform=MNIST_transform)\n",
    "\n",
    "# Creating a dataloader\n",
    "notMNIST_test_loader = torch.utils.data.dataloader.DataLoader(\n",
    "                            dataset=notMNIST_test,\n",
    "                            batch_size=BATCH_SIZE_TEST_KMNIST,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = MNIST_test.targets.numpy()\n",
    "targets_FMNIST = FMNIST_test.targets.numpy()\n",
    "targets_notMNIST = notMNIST_test.targets.numpy().astype(int)\n",
    "targets_KMNIST = KMNIST_test.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_test_in_MAP = predict_MAP(mnist_model, MNIST_test_loader, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_MAP = predict_MAP(mnist_model, FMNIST_test_loader, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_MAP = predict_MAP(mnist_model, notMNIST_test_loader, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_MAP = predict_MAP(mnist_model, KMNIST_test_loader, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03344982489943504\n",
      "4.6731367111206055\n",
      "6.672377586364746\n",
      "6.748490810394287\n"
     ]
    }
   ],
   "source": [
    "# compute average log-likelihood for Diag\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_MAP)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_MAP)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_MAP)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_MAP)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009983010101010131\n",
      "0.5903608484848487\n",
      "0.6404300589747076\n",
      "0.6294307171717172\n"
     ]
    }
   ],
   "source": [
    "#compute the Expected confidence estimate\n",
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_MAP))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_MAP))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_MAP))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1311, 0.9366349875926971)\n"
     ]
    }
   ],
   "source": [
    "##FPR95\n",
    "print(get_fpr95(MNIST_test_in_MAP, MNIST_test_out_FMNIST_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016874086577445269\n",
      "0.1371215432882309\n",
      "0.14116381108760834\n",
      "0.1430293172597885\n"
     ]
    }
   ],
   "source": [
    "## Brier score\n",
    "print(get_brier(MNIST_test_in_MAP, targets, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_FMNIST_MAP, targets_FMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_notMNIST_MAP, targets_notMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_KMNIST_MAP, targets_KMNIST, n_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP = get_in_dist_values(MNIST_test_in_MAP, targets)\n",
    "acc_out_FMNIST_MAP, prob_correct_out_FMNIST_MAP, ent_out_FMNIST_MAP, MMC_out_FMNIST_MAP, auroc_out_FMNIST_MAP = get_out_dist_values(MNIST_test_in_MAP, MNIST_test_out_FMNIST_MAP, targets_FMNIST)\n",
    "acc_out_notMNIST_MAP, prob_correct_out_notMNIST_MAP, ent_out_notMNIST_MAP, MMC_out_notMNIST_MAP, auroc_out_notMNIST_MAP = get_out_dist_values(MNIST_test_in_MAP, MNIST_test_out_notMNIST_MAP, targets_notMNIST)\n",
    "acc_out_KMNIST_MAP, prob_correct_out_KMNIST_MAP, ent_out_KMNIST_MAP, MMC_out_KMNIST_MAP, auroc_out_KMNIST_MAP = get_out_dist_values(MNIST_test_in_MAP, MNIST_test_out_KMNIST_MAP, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, MAP, MNIST] Accuracy: 0.988; average entropy: 0.047;     MMC: 0.986; Prob @ correct: 0.100\n",
      "[Out-FMNIST, MAP, MNIST] Accuracy: 0.073; Average entropy: 0.972;    MMC: 0.663; AUROC: 0.977; Prob @ correct: 0.100\n",
      "[Out-notMNIST, MAP, MNIST] Accuracy: 0.148; Average entropy: 0.620;    MMC: 0.774; AUROC: 0.914; Prob @ correct: 0.100\n",
      "[Out-KMNIST, MAP, MNIST] Accuracy: 0.093; Average entropy: 0.750;    MMC: 0.723; AUROC: 0.959; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_MAP, prob_correct_in_MAP, ent_in_MAP, MMC_in_MAP, 'MNIST', 'MAP')\n",
    "print_out_dist_values(acc_out_FMNIST_MAP, prob_correct_out_FMNIST_MAP, ent_out_FMNIST_MAP, MMC_out_FMNIST_MAP, auroc_out_FMNIST_MAP, 'MNIST', test='FMNIST', method='MAP')\n",
    "print_out_dist_values(acc_out_notMNIST_MAP, prob_correct_out_notMNIST_MAP, ent_out_notMNIST_MAP, MMC_out_notMNIST_MAP, auroc_out_notMNIST_MAP, 'MNIST', test='notMNIST', method='MAP')\n",
    "print_out_dist_values(acc_out_KMNIST_MAP, prob_correct_out_KMNIST_MAP, ent_out_KMNIST_MAP, MMC_out_KMNIST_MAP, auroc_out_KMNIST_MAP, 'MNIST', test='KMNIST', method='MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diag Hessian Sampling estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_diag = Laplace(mnist_model, 'classification', \n",
    "                     subset_of_weights='last_layer', \n",
    "                     hessian_structure='diag',\n",
    "                     prior_precision=1e-0) # 5e-4 # Choose prior precision according to weight decay\n",
    "la_diag.fit(MNIST_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  1.2002999909999978\n",
      "time:  1.0010222549999988\n",
      "time:  0.5089399970000024\n",
      "time:  0.9723320810000011\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_in_D = predict_samples(la_diag, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_D = predict_samples(la_diag, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_D = predict_samples(la_diag, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_D = predict_samples(la_diag, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060485560446977615\n",
      "3.96065354347229\n",
      "4.334907531738281\n",
      "4.933351993560791\n"
     ]
    }
   ],
   "source": [
    "# compute average log-likelihood for Diag\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_D)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_D)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_D)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_D)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03493014141414141\n",
      "0.46846589898989915\n",
      "0.409833633277876\n",
      "0.43425194949494955\n"
     ]
    }
   ],
   "source": [
    "#compute the Expected confidence estimate\n",
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_D))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_D))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_D))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0022665667347609997\n",
      "0.12107032537460327\n",
      "0.11608327180147171\n",
      "0.12063241004943848\n"
     ]
    }
   ],
   "source": [
    "## Brier score\n",
    "print(get_brier(MNIST_test_in_D, targets, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_FMNIST_D, targets_FMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_notMNIST_D, targets_notMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_KMNIST_D, targets_KMNIST, n_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D = get_in_dist_values(MNIST_test_in_D, targets)\n",
    "acc_out_FMNIST_D, prob_correct_out_FMNIST_D, ent_out_FMNIST_D, MMC_out_FMNIST_D, auroc_out_FMNIST_D = get_out_dist_values(MNIST_test_in_D, MNIST_test_out_FMNIST_D, targets_FMNIST)\n",
    "acc_out_notMNIST_D, prob_correct_out_notMNIST_D, ent_out_notMNIST_D, MMC_out_notMNIST_D, auroc_out_notMNIST_D = get_out_dist_values(MNIST_test_in_D, MNIST_test_out_notMNIST_D, targets_notMNIST)\n",
    "acc_out_KMNIST_D, prob_correct_out_KMNIST_D, ent_out_KMNIST_D, MMC_out_KMNIST_D, auroc_out_KMNIST_D = get_out_dist_values(MNIST_test_in_D, MNIST_test_out_KMNIST_D, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Diag, MNIST] Accuracy: 0.989; average entropy: 0.160;     MMC: 0.956; Prob @ correct: 0.100\n",
      "[Out-fmnist, Diag, MNIST] Accuracy: 0.073; Average entropy: 1.313;    MMC: 0.541; AUROC: 0.975; Prob @ correct: 0.100\n",
      "[Out-notMNIST, Diag, MNIST] Accuracy: 0.149; Average entropy: 1.212;    MMC: 0.559; AUROC: 0.963; Prob @ correct: 0.100\n",
      "[Out-KMNIST, Diag, MNIST] Accuracy: 0.095; Average entropy: 1.272;    MMC: 0.529; AUROC: 0.973; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_D, prob_correct_in_D, ent_in_D, MMC_in_D, 'MNIST', 'Diag')\n",
    "print_out_dist_values(acc_out_FMNIST_D, prob_correct_out_FMNIST_D, ent_out_FMNIST_D, MMC_out_FMNIST_D, auroc_out_FMNIST_D, 'MNIST', test='fmnist', method='Diag')\n",
    "print_out_dist_values(acc_out_notMNIST_D, prob_correct_out_notMNIST_D, ent_out_notMNIST_D, MMC_out_notMNIST_D, auroc_out_notMNIST_D, 'MNIST', test='notMNIST', method='Diag')\n",
    "print_out_dist_values(acc_out_KMNIST_D, prob_correct_out_KMNIST_D, ent_out_KMNIST_D, MMC_out_KMNIST_D, auroc_out_KMNIST_D, 'MNIST', test='KMNIST', method='Diag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFAC Laplace Approximation (sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marius/anaconda3/lib/python3.9/site-packages/laplace/utils.py:137: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180549130/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2499.)\n",
      "  L, W = torch.symeig(M, eigenvectors=True)\n"
     ]
    }
   ],
   "source": [
    "la_kron = Laplace(mnist_model, 'classification', \n",
    "                     subset_of_weights='last_layer', \n",
    "                     hessian_structure='kron',\n",
    "                     prior_precision=5e-0) # 5e-4 # Choose prior precision according to weight decay\n",
    "la_kron.fit(MNIST_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  1.3355387420000007\n",
      "time:  1.3483620710000004\n",
      "time:  1.0776169469999992\n",
      "time:  1.2704046519999999\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_in_KFAC = predict_samples(la_kron, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_KFAC = predict_samples(la_kron, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_KFAC = predict_samples(la_kron, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_KFAC = predict_samples(la_kron, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04870095103979111\n",
      "3.7331199645996094\n",
      "4.36720609664917\n",
      "4.877889156341553\n"
     ]
    }
   ],
   "source": [
    "# compute average log-likelihood for KFAC\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_KFAC)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_KFAC)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_KFAC)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_KFAC)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024422959595959588\n",
      "0.42929906060606066\n",
      "0.40477670855100895\n",
      "0.4167330707070709\n"
     ]
    }
   ],
   "source": [
    "# compute ECE for KFAC\n",
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_KFAC))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_KFAC))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_KFAC))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_KFAC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020646171178668737\n",
      "0.11669006198644638\n",
      "0.11602698266506195\n",
      "0.11858072876930237\n"
     ]
    }
   ],
   "source": [
    "## Brier score\n",
    "print(get_brier(MNIST_test_in_KFAC, targets, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_FMNIST_KFAC, targets_FMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_notMNIST_KFAC, targets_notMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_KMNIST_KFAC, targets_KMNIST, n_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_KFAC, prob_correct_in_KFAC, ent_in_KFAC, MMC_in_KFAC = get_in_dist_values(MNIST_test_in_KFAC, targets)\n",
    "acc_out_FMNIST_KFAC, prob_correct_out_FMNIST_KFAC, ent_out_FMNIST_KFAC, MMC_out_FMNIST_KFAC, auroc_out_FMNIST_KFAC = get_out_dist_values(MNIST_test_in_KFAC, MNIST_test_out_FMNIST_KFAC, targets_FMNIST)\n",
    "acc_out_notMNIST_KFAC, prob_correct_out_notMNIST_KFAC, ent_out_notMNIST_KFAC, MMC_out_notMNIST_KFAC, auroc_out_notMNIST_KFAC = get_out_dist_values(MNIST_test_in_KFAC, MNIST_test_out_notMNIST_KFAC, targets_notMNIST)\n",
    "acc_out_KMNIST_KFAC, prob_correct_out_KMNIST_KFAC, ent_out_KMNIST_KFAC, MMC_out_KMNIST_KFAC, auroc_out_KMNIST_KFAC = get_out_dist_values(MNIST_test_in_KFAC, MNIST_test_out_KMNIST_KFAC, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, KFAC, MNIST] Accuracy: 0.988; average entropy: 0.111;     MMC: 0.967; Prob @ correct: 0.100\n",
      "[Out-fmnist, KFAC, MNIST] Accuracy: 0.072; Average entropy: 1.402;    MMC: 0.501; AUROC: 0.985; Prob @ correct: 0.100\n",
      "[Out-notMNIST, KFAC, MNIST] Accuracy: 0.148; Average entropy: 1.228;    MMC: 0.551; AUROC: 0.969; Prob @ correct: 0.100\n",
      "[Out-KMNIST, KFAC, MNIST] Accuracy: 0.094; Average entropy: 1.315;    MMC: 0.511; AUROC: 0.982; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_KFAC, prob_correct_in_KFAC, ent_in_KFAC, MMC_in_KFAC, 'MNIST', 'KFAC')\n",
    "print_out_dist_values(acc_out_FMNIST_KFAC, prob_correct_out_FMNIST_KFAC, ent_out_FMNIST_KFAC, MMC_out_FMNIST_KFAC, auroc_out_FMNIST_KFAC, 'MNIST', test='fmnist', method='KFAC')\n",
    "print_out_dist_values(acc_out_notMNIST_KFAC, prob_correct_out_notMNIST_KFAC, ent_out_notMNIST_KFAC, MMC_out_notMNIST_KFAC, auroc_out_notMNIST_KFAC, 'MNIST', test='notMNIST', method='KFAC')\n",
    "print_out_dist_values(acc_out_KMNIST_KFAC, prob_correct_out_KMNIST_KFAC, ent_out_KMNIST_KFAC, MMC_out_KMNIST_KFAC, auroc_out_KMNIST_KFAC, 'MNIST', test='KMNIST', method='KFAC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace Bridge (Diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0.8771512819999963\n",
      "time:  0.8695184520000012\n",
      "time:  0.30476124100000135\n",
      "time:  0.888303295\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_in_LB_D = predict_LB(la_diag, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_LB_D = predict_LB(la_diag, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_LB_D = predict_LB(la_diag, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_LB_D = predict_LB(la_diag, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04091636836528778\n",
      "3.654500722885132\n",
      "5.585165977478027\n",
      "5.520288944244385\n"
     ]
    }
   ],
   "source": [
    "# # compute average log-likelihood for LB\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_LB_D)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_LB_D)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_LB_D)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_LB_D)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011439090909090939\n",
      "0.48319700000000004\n",
      "0.6082117478998488\n",
      "0.5931453232323233\n"
     ]
    }
   ],
   "source": [
    "#compute ECE for LB\n",
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_LB_D))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_LB_D))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_LB_D))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_LB_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019700229167938232\n",
      "0.12366575002670288\n",
      "0.13661548495292664\n",
      "0.13839513063430786\n"
     ]
    }
   ],
   "source": [
    "## Brier score\n",
    "print(get_brier(MNIST_test_in_LB_D, targets, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_FMNIST_LB_D, targets_FMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_notMNIST_LB_D, targets_notMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_KMNIST_LB_D, targets_KMNIST, n_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_LB_D, prob_correct_in_LB_D, ent_in_LB_D, MMC_in_LB_D = get_in_dist_values(MNIST_test_in_LB_D, targets)\n",
    "acc_out_FMNIST_LB_D, prob_correct_out_FMNIST_LB_D, ent_out_FMNIST_LB_D, MMC_out_FMNIST_LB_D, auroc_out_FMNIST_LB_D = get_out_dist_values(MNIST_test_in_LB_D, MNIST_test_out_FMNIST_LB_D, targets_FMNIST)\n",
    "acc_out_notMNIST_LB_D, prob_correct_out_notMNIST_LB_D, ent_out_notMNIST_LB_D, MMC_out_notMNIST_LB_D, auroc_out_notMNIST_LB_D = get_out_dist_values(MNIST_test_in_LB_D, MNIST_test_out_notMNIST_LB_D, targets_notMNIST)\n",
    "acc_out_KMNIST_LB_D, prob_correct_out_KMNIST_LB_D, ent_out_KMNIST_LB_D, MMC_out_KMNIST_LB_D, auroc_out_KMNIST_LB_D = get_out_dist_values(MNIST_test_in_LB_D, MNIST_test_out_KMNIST_LB_D, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, LB_D, MNIST] Accuracy: 0.987; average entropy: 0.061;     MMC: 0.982; Prob @ correct: 0.100\n",
      "[Out-fmnist, LB_D, MNIST] Accuracy: 0.082; Average entropy: 1.324;    MMC: 0.565; AUROC: 0.982; Prob @ correct: 0.100\n",
      "[Out-notMNIST, LB_D, MNIST] Accuracy: 0.152; Average entropy: 0.737;    MMC: 0.735; AUROC: 0.931; Prob @ correct: 0.100\n",
      "[Out-KMNIST, LB_D, MNIST] Accuracy: 0.099; Average entropy: 0.866;    MMC: 0.692; AUROC: 0.960; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_LB_D, prob_correct_in_LB_D, ent_in_LB_D, MMC_in_LB_D, 'MNIST', 'LB_D')\n",
    "print_out_dist_values(acc_out_FMNIST_LB_D, prob_correct_out_FMNIST_LB_D, ent_out_FMNIST_LB_D, MMC_out_FMNIST_LB_D, auroc_out_FMNIST_LB_D, 'MNIST', test='fmnist', method='LB_D')\n",
    "print_out_dist_values(acc_out_notMNIST_LB_D, prob_correct_out_notMNIST_LB_D, ent_out_notMNIST_LB_D, MMC_out_notMNIST_LB_D, auroc_out_notMNIST_LB_D, 'MNIST', test='notMNIST', method='LB_D')\n",
    "print_out_dist_values(acc_out_KMNIST_LB_D, prob_correct_out_KMNIST_LB_D, ent_out_KMNIST_LB_D, MMC_out_KMNIST_LB_D, auroc_out_KMNIST_LB_D, 'MNIST', test='KMNIST', method='LB_D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LB diag norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0.9353996910000006\n",
      "time:  0.9184220670000016\n",
      "time:  0.3646903100000003\n",
      "time:  0.9031150509999932\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_in_LB_Dn = predict_LB_norm(la_diag, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_LB_Dn = predict_LB_norm(la_diag, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_LB_Dn = predict_LB_norm(la_diag, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_LB_Dn = predict_LB_norm(la_diag, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07220260798931122\n",
      "3.6098625659942627\n",
      "3.163008451461792\n",
      "3.329798460006714\n"
     ]
    }
   ],
   "source": [
    "# # compute average log-likelihood for LB\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_LB_Dn)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_LB_Dn)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_LB_Dn)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_LB_Dn)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04084181818181817\n",
      "0.5142652929292929\n",
      "0.37737078108579925\n",
      "0.3928338787878788\n"
     ]
    }
   ],
   "source": [
    "#compute ECE for LB\n",
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_LB_Dn))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_LB_Dn))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_LB_Dn))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_LB_Dn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002524588257074356\n",
      "0.1262955218553543\n",
      "0.112608402967453\n",
      "0.11521024256944656\n"
     ]
    }
   ],
   "source": [
    "## Brier score\n",
    "print(get_brier(MNIST_test_in_LB_Dn, targets, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_FMNIST_LB_Dn, targets_FMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_notMNIST_LB_Dn, targets_notMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_KMNIST_LB_Dn, targets_KMNIST, n_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_LB_D, prob_correct_in_LB_D, ent_in_LB_D, MMC_in_LB_D = get_in_dist_values(MNIST_test_in_LB_Dn, targets)\n",
    "acc_out_FMNIST_LB_D, prob_correct_out_FMNIST_LB_D, ent_out_FMNIST_LB_D, MMC_out_FMNIST_LB_D, auroc_out_FMNIST_LB_D = get_out_dist_values(MNIST_test_in_LB_Dn, MNIST_test_out_FMNIST_LB_Dn, targets_FMNIST)\n",
    "acc_out_notMNIST_LB_D, prob_correct_out_notMNIST_LB_D, ent_out_notMNIST_LB_D, MMC_out_notMNIST_LB_D, auroc_out_notMNIST_LB_D = get_out_dist_values(MNIST_test_in_LB_Dn, MNIST_test_out_notMNIST_LB_Dn, targets_notMNIST)\n",
    "acc_out_KMNIST_LB_D, prob_correct_out_KMNIST_LB_D, ent_out_KMNIST_LB_D, MMC_out_KMNIST_LB_D, auroc_out_KMNIST_LB_D = get_out_dist_values(MNIST_test_in_LB_Dn, MNIST_test_out_KMNIST_LB_Dn, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, LB_D, MNIST] Accuracy: 0.987; average entropy: 0.213;     MMC: 0.949; Prob @ correct: 0.100\n",
      "[Out-fmnist, LB_D, MNIST] Accuracy: 0.086; Average entropy: 1.243;    MMC: 0.600; AUROC: 0.953; Prob @ correct: 0.100\n",
      "[Out-notMNIST, LB_D, MNIST] Accuracy: 0.138; Average entropy: 1.459;    MMC: 0.515; AUROC: 0.954; Prob @ correct: 0.100\n",
      "[Out-KMNIST, LB_D, MNIST] Accuracy: 0.098; Average entropy: 1.506;    MMC: 0.491; AUROC: 0.971; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_LB_D, prob_correct_in_LB_D, ent_in_LB_D, MMC_in_LB_D, 'MNIST', 'LB_D')\n",
    "print_out_dist_values(acc_out_FMNIST_LB_D, prob_correct_out_FMNIST_LB_D, ent_out_FMNIST_LB_D, MMC_out_FMNIST_LB_D, auroc_out_FMNIST_LB_D, 'MNIST', test='fmnist', method='LB_D')\n",
    "print_out_dist_values(acc_out_notMNIST_LB_D, prob_correct_out_notMNIST_LB_D, ent_out_notMNIST_LB_D, MMC_out_notMNIST_LB_D, auroc_out_notMNIST_LB_D, 'MNIST', test='notMNIST', method='LB_D')\n",
    "print_out_dist_values(acc_out_KMNIST_LB_D, prob_correct_out_KMNIST_LB_D, ent_out_KMNIST_LB_D, MMC_out_KMNIST_LB_D, auroc_out_KMNIST_LB_D, 'MNIST', test='KMNIST', method='LB_D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFAC Laplace Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0.9228590539999999\n",
      "time:  0.9338816940000001\n",
      "time:  0.6778247060000027\n",
      "time:  0.9153987969999946\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_in_LB_KFAC = predict_LB(la_kron, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_LB_KFAC = predict_LB(la_kron, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_LB_KFAC = predict_LB(la_kron, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_LB_KFAC = predict_LB(la_kron, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03415154293179512\n",
      "3.8378238677978516\n",
      "6.014162063598633\n",
      "6.023524284362793\n"
     ]
    }
   ],
   "source": [
    "# compute average log-likelihood for LB KFAC\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_LB_KFAC)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_LB_KFAC)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_LB_KFAC)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_LB_KFAC)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011948898989899039\n",
      "0.5424864242424243\n",
      "0.6367586083004797\n",
      "0.6168500707070707\n"
     ]
    }
   ],
   "source": [
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_LB_KFAC))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_LB_KFAC))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_LB_KFAC))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_LB_KFAC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001700085704214871\n",
      "0.13170121610164642\n",
      "0.14033333957195282\n",
      "0.14197257161140442\n"
     ]
    }
   ],
   "source": [
    "## Brier score\n",
    "print(get_brier(MNIST_test_in_LB_KFAC, targets, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_FMNIST_LB_KFAC, targets_FMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_notMNIST_LB_KFAC, targets_notMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_KMNIST_LB_KFAC, targets_KMNIST, n_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_LB_KFAC, prob_correct_in_LB_KFAC, ent_in_LB_KFAC, MMC_in_LB_KFAC = get_in_dist_values(MNIST_test_in_LB_KFAC, targets)\n",
    "acc_out_FMNIST_LB_KFAC, prob_correct_out_FMNIST_LB_KFAC, ent_out_FMNIST_LB_KFAC, MMC_out_FMNIST_LB_KFAC, auroc_out_FMNIST_LB_KFAC = get_out_dist_values(MNIST_test_in_LB_KFAC, MNIST_test_out_FMNIST_LB_KFAC, targets_FMNIST)\n",
    "acc_out_notMNIST_LB_KFAC, prob_correct_out_notMNIST_LB_KFAC, ent_out_notMNIST_LB_KFAC, MMC_out_notMNIST_LB_KFAC, auroc_out_notMNIST_LB_KFAC = get_out_dist_values(MNIST_test_in_LB_KFAC, MNIST_test_out_notMNIST_LB_KFAC, targets_notMNIST)\n",
    "acc_out_KMNIST_LB_KFAC, prob_correct_out_KMNIST_LB_KFAC, ent_out_KMNIST_LB_KFAC, MMC_out_KMNIST_LB_KFAC, auroc_out_KMNIST_LB_KFAC = get_out_dist_values(MNIST_test_in_LB_KFAC, MNIST_test_out_KMNIST_LB_KFAC, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, LB_KFAC, MNIST] Accuracy: 0.988; average entropy: 0.051;     MMC: 0.985; Prob @ correct: 0.100\n",
      "[Out-fmnist, LB_KFAC, MNIST] Accuracy: 0.075; Average entropy: 1.202;    MMC: 0.617; AUROC: 0.978; Prob @ correct: 0.100\n",
      "[Out-notMNIST, LB_KFAC, MNIST] Accuracy: 0.147; Average entropy: 0.685;    MMC: 0.757; AUROC: 0.912; Prob @ correct: 0.100\n",
      "[Out-KMNIST, LB_KFAC, MNIST] Accuracy: 0.094; Average entropy: 0.806;    MMC: 0.711; AUROC: 0.957; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_LB_KFAC, prob_correct_in_LB_KFAC, ent_in_LB_KFAC, MMC_in_LB_KFAC, 'MNIST', 'LB_KFAC')\n",
    "print_out_dist_values(acc_out_FMNIST_LB_KFAC, prob_correct_out_FMNIST_LB_KFAC, ent_out_FMNIST_LB_KFAC, MMC_out_FMNIST_LB_KFAC, auroc_out_FMNIST_LB_KFAC, 'MNIST', test='fmnist', method='LB_KFAC')\n",
    "print_out_dist_values(acc_out_notMNIST_LB_KFAC, prob_correct_out_notMNIST_LB_KFAC, ent_out_notMNIST_LB_KFAC, MMC_out_notMNIST_LB_KFAC, auroc_out_notMNIST_LB_KFAC, 'MNIST', test='notMNIST', method='LB_KFAC')\n",
    "print_out_dist_values(acc_out_KMNIST_LB_KFAC, prob_correct_out_KMNIST_LB_KFAC, ent_out_KMNIST_LB_KFAC, MMC_out_KMNIST_LB_KFAC, auroc_out_KMNIST_LB_KFAC, 'MNIST', test='KMNIST', method='LB_KFAC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LB kfac norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  1.2208120379999983\n",
      "time:  1.2360889580000034\n",
      "time:  0.890107215999997\n",
      "time:  1.3019489289999981\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_in_LB_KFACn = predict_LB_norm(la_kron, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_LB_KFACn = predict_LB_norm(la_kron, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_LB_KFACn = predict_LB_norm(la_kron, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_LB_KFACn = predict_LB_norm(la_kron, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0359264612197876\n",
      "3.2363293170928955\n",
      "3.2359938621520996\n",
      "3.617896795272827\n"
     ]
    }
   ],
   "source": [
    "# compute average log-likelihood for LB KFAC\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_LB_KFACn)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_LB_KFACn)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_LB_KFACn)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_LB_KFACn)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012604787878787842\n",
      "0.46441325252525256\n",
      "0.3865528226076186\n",
      "0.4096595454545455\n"
     ]
    }
   ],
   "source": [
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_LB_KFACn))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_LB_KFACn))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_LB_KFACn))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_LB_KFACn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00174651516135782\n",
      "0.12144472450017929\n",
      "0.11362239718437195\n",
      "0.11815816164016724\n"
     ]
    }
   ],
   "source": [
    "## Brier score\n",
    "print(get_brier(MNIST_test_in_LB_KFACn, targets, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_FMNIST_LB_KFACn, targets_FMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_notMNIST_LB_KFACn, targets_notMNIST, n_classes=10))\n",
    "print(get_brier(MNIST_test_out_KMNIST_LB_KFACn, targets_KMNIST, n_classes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_LB_KFAC, prob_correct_in_LB_KFAC, ent_in_LB_KFAC, MMC_in_LB_KFAC = get_in_dist_values(MNIST_test_in_LB_KFACn, targets)\n",
    "acc_out_FMNIST_LB_KFAC, prob_correct_out_FMNIST_LB_KFAC, ent_out_FMNIST_LB_KFAC, MMC_out_FMNIST_LB_KFAC, auroc_out_FMNIST_LB_KFAC = get_out_dist_values(MNIST_test_in_LB_KFACn, MNIST_test_out_FMNIST_LB_KFACn, targets_FMNIST)\n",
    "acc_out_notMNIST_LB_KFAC, prob_correct_out_notMNIST_LB_KFAC, ent_out_notMNIST_LB_KFAC, MMC_out_notMNIST_LB_KFAC, auroc_out_notMNIST_LB_KFAC = get_out_dist_values(MNIST_test_in_LB_KFACn, MNIST_test_out_notMNIST_LB_KFACn, targets_notMNIST)\n",
    "acc_out_KMNIST_LB_KFAC, prob_correct_out_KMNIST_LB_KFAC, ent_out_KMNIST_LB_KFAC, MMC_out_KMNIST_LB_KFAC, auroc_out_KMNIST_LB_KFAC = get_out_dist_values(MNIST_test_in_LB_KFACn, MNIST_test_out_KMNIST_LB_KFACn, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, LB_KFAC, MNIST] Accuracy: 0.988; average entropy: 0.061;     MMC: 0.982; Prob @ correct: 0.100\n",
      "[Out-fmnist, LB_KFAC, MNIST] Accuracy: 0.077; Average entropy: 1.469;    MMC: 0.541; AUROC: 0.986; Prob @ correct: 0.100\n",
      "[Out-notMNIST, LB_KFAC, MNIST] Accuracy: 0.145; Average entropy: 1.476;    MMC: 0.508; AUROC: 0.981; Prob @ correct: 0.100\n",
      "[Out-KMNIST, LB_KFAC, MNIST] Accuracy: 0.090; Average entropy: 1.477;    MMC: 0.500; AUROC: 0.988; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_LB_KFAC, prob_correct_in_LB_KFAC, ent_in_LB_KFAC, MMC_in_LB_KFAC, 'MNIST', 'LB_KFAC')\n",
    "print_out_dist_values(acc_out_FMNIST_LB_KFAC, prob_correct_out_FMNIST_LB_KFAC, ent_out_FMNIST_LB_KFAC, MMC_out_FMNIST_LB_KFAC, auroc_out_FMNIST_LB_KFAC, 'MNIST', test='fmnist', method='LB_KFAC')\n",
    "print_out_dist_values(acc_out_notMNIST_LB_KFAC, prob_correct_out_notMNIST_LB_KFAC, ent_out_notMNIST_LB_KFAC, MMC_out_notMNIST_LB_KFAC, auroc_out_notMNIST_LB_KFAC, 'MNIST', test='notMNIST', method='LB_KFAC')\n",
    "print_out_dist_values(acc_out_KMNIST_LB_KFAC, prob_correct_out_KMNIST_LB_KFAC, ent_out_KMNIST_LB_KFAC, MMC_out_KMNIST_LB_KFAC, auroc_out_KMNIST_LB_KFAC, 'MNIST', test='KMNIST', method='LB_KFAC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to probit (extended MacKay approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  1.1141732800000028\n",
      "time:  1.1267198460000003\n",
      "time:  0.3676808479999991\n",
      "time:  1.0509229290000022\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_in_PROBIT_D = predict_probit(la_diag, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_PROBIT_D = predict_probit(la_diag, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_PROBIT_D = predict_probit(la_diag, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_PROBIT_D = predict_probit(la_diag, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04973114654421806\n",
      "3.832324266433716\n",
      "3.872626781463623\n",
      "4.313175201416016\n"
     ]
    }
   ],
   "source": [
    "# compute average log-likelihood for LB KFAC\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_PROBIT_D)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_PROBIT_D)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_PROBIT_D)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_PROBIT_D)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023886616161616154\n",
      "0.5246621717171718\n",
      "0.4899368983576419\n",
      "0.4909745050505051\n"
     ]
    }
   ],
   "source": [
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_PROBIT_D))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_PROBIT_D))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_PROBIT_D))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_PROBIT_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_PROBIT, prob_correct_in_PROBIT, ent_in_PROBIT, MMC_in_PROBIT = get_in_dist_values(MNIST_test_in_PROBIT_D, targets)\n",
    "acc_out_FMNIST_PROBIT, prob_correct_out_FMNIST_PROBIT, ent_out_FMNIST_PROBIT, MMC_out_FMNIST_PROBIT, auroc_out_FMNIST_PROBIT = get_out_dist_values(MNIST_test_in_PROBIT_D, MNIST_test_out_FMNIST_PROBIT_D, targets_FMNIST)\n",
    "acc_out_notMNIST_PROBIT, prob_correct_out_notMNIST_PROBIT, ent_out_notMNIST_PROBIT, MMC_out_notMNIST_PROBIT, auroc_out_notMNIST_PROBIT = get_out_dist_values(MNIST_test_in_PROBIT_D, MNIST_test_out_notMNIST_PROBIT_D, targets_notMNIST)\n",
    "acc_out_KMNIST_PROBIT, prob_correct_out_KMNIST_PROBIT, ent_out_KMNIST_PROBIT, MMC_out_KMNIST_PROBIT, auroc_out_KMNIST_PROBIT = get_out_dist_values(MNIST_test_in_PROBIT_D, MNIST_test_out_KMNIST_PROBIT_D, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, PROBIT, MNIST] Accuracy: 0.987; average entropy: 0.126;     MMC: 0.967; Prob @ correct: 0.100\n",
      "[Out-fmnist, PROBIT, MNIST] Accuracy: 0.073; Average entropy: 1.214;    MMC: 0.598; AUROC: 0.971; Prob @ correct: 0.100\n",
      "[Out-notMNIST, PROBIT, MNIST] Accuracy: 0.141; Average entropy: 1.116;    MMC: 0.620; AUROC: 0.957; Prob @ correct: 0.100\n",
      "[Out-KMNIST, PROBIT, MNIST] Accuracy: 0.092; Average entropy: 1.192;    MMC: 0.583; AUROC: 0.969; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_PROBIT, prob_correct_in_PROBIT, ent_in_PROBIT, MMC_in_PROBIT, 'MNIST', 'PROBIT')\n",
    "print_out_dist_values(acc_out_FMNIST_PROBIT, prob_correct_out_FMNIST_PROBIT, ent_out_FMNIST_PROBIT, MMC_out_FMNIST_PROBIT, auroc_out_FMNIST_PROBIT, 'MNIST', test='fmnist', method='PROBIT')\n",
    "print_out_dist_values(acc_out_notMNIST_PROBIT, prob_correct_out_notMNIST_PROBIT, ent_out_notMNIST_PROBIT, MMC_out_notMNIST_PROBIT, auroc_out_notMNIST_PROBIT, 'MNIST', test='notMNIST', method='PROBIT')\n",
    "print_out_dist_values(acc_out_KMNIST_PROBIT, prob_correct_out_KMNIST_PROBIT, ent_out_KMNIST_PROBIT, MMC_out_KMNIST_PROBIT, auroc_out_KMNIST_PROBIT, 'MNIST', test='KMNIST', method='PROBIT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBIT KFAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  1.175833780000005\n",
      "time:  1.131725528000004\n",
      "time:  0.6892226630000025\n",
      "time:  1.0696401479999977\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_in_PROBIT_K = predict_probit(la_kron, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_PROBIT_K = predict_probit(la_kron, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_PROBIT_K = predict_probit(la_kron, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_PROBIT_K = predict_probit(la_kron, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4061307907104492\n",
      "2.7053489685058594\n",
      "2.7153563499450684\n",
      "2.879185199737549\n"
     ]
    }
   ],
   "source": [
    "# compute average log-likelihood for LB KFAC\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_PROBIT_K)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_PROBIT_K)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_PROBIT_K)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_PROBIT_K)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3033561919191919\n",
      "0.27609011111111115\n",
      "0.24635375329885054\n",
      "0.23612531313131316\n"
     ]
    }
   ],
   "source": [
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_PROBIT_K))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_PROBIT_K))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_PROBIT_K))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_PROBIT_K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_PROBIT, prob_correct_in_PROBIT, ent_in_PROBIT, MMC_in_PROBIT = get_in_dist_values(MNIST_test_in_PROBIT_K, targets)\n",
    "acc_out_FMNIST_PROBIT, prob_correct_out_FMNIST_PROBIT, ent_out_FMNIST_PROBIT, MMC_out_FMNIST_PROBIT, auroc_out_FMNIST_PROBIT = get_out_dist_values(MNIST_test_in_PROBIT_K, MNIST_test_out_FMNIST_PROBIT_K, targets_FMNIST)\n",
    "acc_out_notMNIST_PROBIT, prob_correct_out_notMNIST_PROBIT, ent_out_notMNIST_PROBIT, MMC_out_notMNIST_PROBIT, auroc_out_notMNIST_PROBIT = get_out_dist_values(MNIST_test_in_PROBIT_K, MNIST_test_out_notMNIST_PROBIT_K, targets_notMNIST)\n",
    "acc_out_KMNIST_PROBIT, prob_correct_out_KMNIST_PROBIT, ent_out_KMNIST_PROBIT, MMC_out_KMNIST_PROBIT, auroc_out_KMNIST_PROBIT = get_out_dist_values(MNIST_test_in_PROBIT_K, MNIST_test_out_KMNIST_PROBIT_K, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, PROBIT, MNIST] Accuracy: 0.988; average entropy: 1.155;     MMC: 0.685; Prob @ correct: 0.100\n",
      "[Out-fmnist, PROBIT, MNIST] Accuracy: 0.073; Average entropy: 1.890;    MMC: 0.349; AUROC: 0.962; Prob @ correct: 0.100\n",
      "[Out-notMNIST, PROBIT, MNIST] Accuracy: 0.148; Average entropy: 1.805;    MMC: 0.376; AUROC: 0.929; Prob @ correct: 0.100\n",
      "[Out-KMNIST, PROBIT, MNIST] Accuracy: 0.093; Average entropy: 1.891;    MMC: 0.328; AUROC: 0.966; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_PROBIT, prob_correct_in_PROBIT, ent_in_PROBIT, MMC_in_PROBIT, 'MNIST', 'PROBIT')\n",
    "print_out_dist_values(acc_out_FMNIST_PROBIT, prob_correct_out_FMNIST_PROBIT, ent_out_FMNIST_PROBIT, MMC_out_FMNIST_PROBIT, auroc_out_FMNIST_PROBIT, 'MNIST', test='fmnist', method='PROBIT')\n",
    "print_out_dist_values(acc_out_notMNIST_PROBIT, prob_correct_out_notMNIST_PROBIT, ent_out_notMNIST_PROBIT, MMC_out_notMNIST_PROBIT, auroc_out_notMNIST_PROBIT, 'MNIST', test='notMNIST', method='PROBIT')\n",
    "print_out_dist_values(acc_out_KMNIST_PROBIT, prob_correct_out_KMNIST_PROBIT, ent_out_KMNIST_PROBIT, MMC_out_KMNIST_PROBIT, auroc_out_KMNIST_PROBIT, 'MNIST', test='KMNIST', method='PROBIT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_6801/668683560.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to Second-order Delta Posterior Predictive\n",
    "\n",
    "this kinda sucks. So we'll just leave it alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_test_in_SODPP_D = predict_second_order_dpp(la_diag, MNIST_test_loader, timing=True, device=device).cpu().nan_to_num(nan=0.0, neginf=0.0, posinf=1.0).numpy()\n",
    "MNIST_test_out_FMNIST_SODPP_D = predict_second_order_dpp(la_diag, FMNIST_test_loader, timing=True, device=device).cpu().nan_to_num(nan=0.0, neginf=0.0, posinf=1.0).numpy()\n",
    "MNIST_test_out_notMNIST_SODPP_D = predict_second_order_dpp(la_diag, notMNIST_test_loader, timing=True, device=device).cpu().nan_to_num(nan=0.0, neginf=0.0, posinf=1.0).numpy()\n",
    "MNIST_test_out_KMNIST_SODPP_D = predict_second_order_dpp(la_diag, KMNIST_test_loader, timing=True, device=device).cpu().nan_to_num(nan=0.0, neginf=0.0, posinf=1.0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average log-likelihood for LB KFAC\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_SODPP_D)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_SODPP_D)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_SODPP_D)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_SODPP_D)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_SODPP_D))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_SODPP_D))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_SODPP_D))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_SODPP_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_SODPP, prob_correct_in_SODPP, ent_in_SODPP, MMC_in_SODPP = get_in_dist_values(MNIST_test_in_SODPP_D, targets)\n",
    "acc_out_FMNIST_SODPP, prob_correct_out_FMNIST_SODPP, ent_out_FMNIST_SODPP, MMC_out_FMNIST_SODPP, auroc_out_FMNIST_SODPP = get_out_dist_values(MNIST_test_in_SODPP_D, MNIST_test_out_FMNIST_SODPP_D, targets_FMNIST)\n",
    "acc_out_notMNIST_SODPP, prob_correct_out_notMNIST_SODPP, ent_out_notMNIST_SODPP, MMC_out_notMNIST_SODPP, auroc_out_notMNIST_SODPP = get_out_dist_values(MNIST_test_in_SODPP_D, MNIST_test_out_notMNIST_SODPP_D, targets_notMNIST)\n",
    "acc_out_KMNIST_SODPP, prob_correct_out_KMNIST_SODPP, ent_out_KMNIST_SODPP, MMC_out_KMNIST_SODPP, auroc_out_KMNIST_SODPP = get_out_dist_values(MNIST_test_in_SODPP_D, MNIST_test_out_KMNIST_SODPP_D, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in_dist_values(acc_in_SODPP, prob_correct_in_SODPP, ent_in_SODPP, MMC_in_SODPP, 'MNIST', 'SODPP')\n",
    "print_out_dist_values(acc_out_FMNIST_SODPP, prob_correct_out_FMNIST_SODPP, ent_out_FMNIST_SODPP, MMC_out_FMNIST_SODPP, auroc_out_FMNIST_SODPP, 'MNIST', test='fmnist', method='SODPP')\n",
    "print_out_dist_values(acc_out_notMNIST_SODPP, prob_correct_out_notMNIST_SODPP, ent_out_notMNIST_SODPP, MMC_out_notMNIST_SODPP, auroc_out_notMNIST_SODPP, 'MNIST', test='notMNIST', method='SODPP')\n",
    "print_out_dist_values(acc_out_KMNIST_SODPP, prob_correct_out_KMNIST_SODPP, ent_out_KMNIST_SODPP, MMC_out_KMNIST_SODPP, auroc_out_KMNIST_SODPP, 'MNIST', test='KMNIST', method='SODPP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFAC SODPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_test_in_SODPP_K = predict_second_order_dpp(la_kron, MNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_FMNIST_SODPP_K = predict_second_order_dpp(la_kron, FMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_notMNIST_SODPP_K = predict_second_order_dpp(la_kron, notMNIST_test_loader, timing=True, device=device).cpu().numpy()\n",
    "MNIST_test_out_KMNIST_SODPP_K = predict_second_order_dpp(la_kron, KMNIST_test_loader, timing=True, device=device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average log-likelihood for LB KFAC\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_in_SODPP_K)).log_prob(torch.tensor(targets)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_FMNIST_SODPP_K)).log_prob(torch.tensor(targets_FMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_notMNIST_SODPP_K)).log_prob(torch.tensor(targets_notMNIST)).mean().item())\n",
    "print(-torch.distributions.Categorical(torch.tensor(MNIST_test_out_KMNIST_SODPP_K)).log_prob(torch.tensor(targets_KMNIST)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scoring.expected_calibration_error(targets, MNIST_test_in_SODPP_K))\n",
    "print(scoring.expected_calibration_error(targets_FMNIST, MNIST_test_out_FMNIST_SODPP_K))\n",
    "print(scoring.expected_calibration_error(targets_notMNIST, MNIST_test_out_notMNIST_SODPP_K))\n",
    "print(scoring.expected_calibration_error(targets_KMNIST, MNIST_test_out_KMNIST_SODPP_K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_SODPP, prob_correct_in_SODPP, ent_in_SODPP, MMC_in_SODPP = get_in_dist_values(MNIST_test_in_SODPP_K, targets)\n",
    "acc_out_FMNIST_SODPP, prob_correct_out_FMNIST_SODPP, ent_out_FMNIST_SODPP, MMC_out_FMNIST_SODPP, auroc_out_FMNIST_SODPP = get_out_dist_values(MNIST_test_in_SODPP_K, MNIST_test_out_FMNIST_SODPP_K, targets_FMNIST)\n",
    "acc_out_notMNIST_SODPP, prob_correct_out_notMNIST_SODPP, ent_out_notMNIST_SODPP, MMC_out_notMNIST_SODPP, auroc_out_notMNIST_SODPP = get_out_dist_values(MNIST_test_in_SODPP_K, MNIST_test_out_notMNIST_SODPP_K, targets_notMNIST)\n",
    "acc_out_KMNIST_SODPP, prob_correct_out_KMNIST_SODPP, ent_out_KMNIST_SODPP, MMC_out_KMNIST_SODPP, auroc_out_KMNIST_SODPP = get_out_dist_values(MNIST_test_in_SODPP_K, MNIST_test_out_KMNIST_SODPP_K, targets_KMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in_dist_values(acc_in_SODPP, prob_correct_in_SODPP, ent_in_SODPP, MMC_in_SODPP, 'MNIST', 'SODPP')\n",
    "print_out_dist_values(acc_out_FMNIST_SODPP, prob_correct_out_FMNIST_SODPP, ent_out_FMNIST_SODPP, MMC_out_FMNIST_SODPP, auroc_out_FMNIST_SODPP, 'MNIST', test='fmnist', method='SODPP')\n",
    "print_out_dist_values(acc_out_notMNIST_SODPP, prob_correct_out_notMNIST_SODPP, ent_out_notMNIST_SODPP, MMC_out_notMNIST_SODPP, auroc_out_notMNIST_SODPP, 'MNIST', test='notMNIST', method='SODPP')\n",
    "print_out_dist_values(acc_out_KMNIST_SODPP, prob_correct_out_KMNIST_SODPP, ent_out_KMNIST_SODPP, MMC_out_KMNIST_SODPP, auroc_out_KMNIST_SODPP, 'MNIST', test='KMNIST', method='SODPP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
