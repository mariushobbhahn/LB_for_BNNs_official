{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3141,
     "status": "ok",
     "timestamp": 1591121107207,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "SFT2Q81Nhmk6",
    "outputId": "9b3dc7c0-84a5-4d3b-9dfa-f02a7bfb85ae"
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi\n",
    "#using a GeForce GTX1080 Ti for reproducibility for all timing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7628,
     "status": "ok",
     "timestamp": 1591121113311,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "HkOPiDW8c_FB",
    "outputId": "04c23712-a918-4346-bb86-69e8753d95dd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from utils.LB_utils import * \n",
    "from utils.load_not_MNIST import notMNIST\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from laplace import Laplace\n",
    "\n",
    "s = 1\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "cuda status:  True\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cuda_status = torch.cuda.is_available()\n",
    "print(\"device: \", device)\n",
    "print(\"cuda status: \", cuda_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8E81UKkc_Fe"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btXBVjRZc_Ff"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN_CIFAR10 = 128\n",
    "BATCH_SIZE_TEST_CIFAR10 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9830,
     "status": "ok",
     "timestamp": 1591121117173,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "JJ82fe_uc_GQ",
    "outputId": "bcf6359a-7843-416a-e24a-0decc7353b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "#~/data/cifar10\n",
    "CIFAR10_trainset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=True, download=True, transform=transform_train)\n",
    "CIFAR10_train_loader = torch.utils.data.DataLoader(CIFAR10_trainset, batch_size=BATCH_SIZE_TRAIN_CIFAR10, shuffle=True, num_workers=2)\n",
    "\n",
    "#~/data/cifar10\n",
    "CIFAR10_testset = torchvision.datasets.CIFAR10(root='~/data/cifar10', train=False, download=True, transform=transform_test)\n",
    "CIFAR10_test_loader = torch.utils.data.DataLoader(CIFAR10_testset, batch_size=BATCH_SIZE_TEST_CIFAR10, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "dataiter = iter(CIFAR10_train_loader)\n",
    "images, labels = dataiter.next()\n",
    "nrow = int(BATCH_SIZE_TRAIN_CIFAR10/4)\n",
    "imshow(torchvision.utils.make_grid(images, nrow=nrow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySv8B-GHc_HE"
   },
   "source": [
    "# Train CIFAR10 on ResNet18 (or load weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchvision.models as models\n",
    "import resnet18_v2\n",
    "CIFAR10_model = resnet18_v2.ResNet18().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORChHBtxc_Hp"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(CIFAR10_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "MAX_EPOCHS=200\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCHS)\n",
    "best_acc = 0  # best test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2E-2hK3c_H7"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(net):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(CIFAR10_train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    \n",
    "    print(\"train loss: \", train_loss)\n",
    "    print(\"train accuracy: \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvrM1bILc_IO"
   },
   "outputs": [],
   "source": [
    "def test(net, path, save=False):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(CIFAR10_test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        acc = correct/total\n",
    "        if acc > best_acc and save: \n",
    "            best_acc = acc\n",
    "            print(\"saving model at: {}\".format(path))\n",
    "            torch.save(net.state_dict(), path)\n",
    "\n",
    "\n",
    "        print(\"test loss: \", test_loss)\n",
    "        print(\"current acc: {}; best acc: {}\".format(acc, best_acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5_u3JBfc_IU"
   },
   "outputs": [],
   "source": [
    "# We know that you should not validate on your test data but our paper is not about the training process\n",
    "# but rather about what you can do once you have a well-trained model. \n",
    "\n",
    "def train_all():\n",
    "    CIFAR10_PATH = 'pretrained_weights/CIFAR10_resnet18_s{}.pth'.format(s)\n",
    "    CIFAR10_PATH_BEST = 'pretrained_weights/CIFAR10_resnet18_best_s{}.pth'.format(s)\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        train(CIFAR10_model)\n",
    "        test(CIFAR10_model, save=True, path=CIFAR10_PATH_BEST)\n",
    "        scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBhBW8yFc_Ib"
   },
   "outputs": [],
   "source": [
    "##### uncomment this if you want to train a network ######\n",
    "\n",
    "#t0 = time.time()\n",
    "#train_all()\n",
    "#t1 = time.time()\n",
    "#print(\"training took: {} seconds\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training took: 4288.249864578247 seconds which is 71.47 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24560,
     "status": "ok",
     "timestamp": 1591121138024,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "Ygkql29Oc_Ih",
    "outputId": "f83ef7dc-e3b5-4cbc-9c3c-85a5f408edd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: pretrained_weights/CIFAR10_resnet18_best_s1.pth\n",
      "test loss:  15.19917606934905\n",
      "current acc: 0.9517; best acc: 0\n"
     ]
    }
   ],
   "source": [
    "##### if you already have a trained model ##############\n",
    "#CIFAR10_PATH = 'pretrained_weights/CIFAR10_resnet18_pretrained.pth'\n",
    "CIFAR10_PATH = 'pretrained_weights/CIFAR10_resnet18_best_s{}.pth'.format(s)\n",
    "CIFAR10_model = resnet18_v2.ResNet18().to(device)\n",
    "print(\"loading model from: {}\".format(CIFAR10_PATH))\n",
    "CIFAR10_model.load_state_dict(torch.load(CIFAR10_PATH))#, map_location=torch.device('cpu')))\n",
    "#test the model\n",
    "test(CIFAR10_model, save=False, path=CIFAR10_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YasrUI_6c_Ir"
   },
   "source": [
    "# prepare Gaussians (Diag)\n",
    "\n",
    "If you want to play around with other settings you can change the prior variance var0 here. Note that the prior variance for Diagonal or KFAC Hessian can be quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backpack.extensions import DiagGGNExact\n",
    "\n",
    "def Diag_second_order(model, train_loader, var0 = 10, device='cpu'):\n",
    "\n",
    "    W = list(model.parameters())[-2]\n",
    "    b = list(model.parameters())[-1]\n",
    "    m, n = W.shape\n",
    "    print(\"n: {} inputs to linear layer with m: {} classes\".format(n, m))\n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    tau = 1/var0\n",
    "\n",
    "    extend(lossfunc, debug=False)\n",
    "    extend(model.linear, debug=False)\n",
    "\n",
    "    #with backpack(DiagHessian()):\n",
    "    #with backpack(DiagGGNMC()):\n",
    "    with backpack(DiagGGNExact()):\n",
    "\n",
    "        max_len = len(train_loader)\n",
    "        weights_cov = torch.zeros(m, n, device=device)\n",
    "        biases_cov = torch.zeros(m, device=device)\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            if device == 'cuda':\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            model.zero_grad()\n",
    "            lossfunc(model(x), y).backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Hessian of weight\n",
    "                W_ = W.diag_ggn_exact\n",
    "                b_ = b.diag_ggn_exact\n",
    "                \n",
    "            #add_prior: since it will be flattened later we can just add the prior like that\n",
    "            W_ += tau * torch.ones(W_.size(), device=device)\n",
    "            b_ += tau * torch.ones(b_.size(), device=device)\n",
    "            \n",
    "            W_inv = 1/W_\n",
    "            b_inv = 1/b_\n",
    "\n",
    "            #rho = min(1-1/(batch_idx+1), 0.995)\n",
    "            rho = 1 - 1/(batch_idx + 1)\n",
    "            #print(\"rho: \", rho)\n",
    "                \n",
    "            weights_cov = rho * weights_cov + (1-rho) * W_inv\n",
    "            biases_cov = rho * biases_cov + (1-rho) * b_inv\n",
    "\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "        \n",
    "            #comment this in if you want to be fast while losing nearly no accuracy\n",
    "            #if batch_idx > 1000: break\n",
    "\n",
    "    # Predictive distribution\n",
    "    with torch.no_grad():\n",
    "        M_W_post = W.t()\n",
    "        M_b_post = b\n",
    "\n",
    "        C_W_post = weights_cov\n",
    "        C_b_post = biases_cov\n",
    "    \n",
    "        print(\"M_W_post size: \", M_W_post.size())\n",
    "        print(\"M_b_post size: \", M_b_post.size())\n",
    "        print(\"C_W_post size: \", C_W_post.size())\n",
    "        print(\"C_b_post size: \", C_b_post.size())\n",
    "\n",
    "    return(M_W_post, M_b_post, C_W_post, C_b_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 512 inputs to linear layer with m: 10 classes\n",
      "rho:  0.0\n",
      "Batch: 0/391\n",
      "rho:  0.5\n",
      "Batch: 1/391\n",
      "rho:  0.6666666666666667\n",
      "Batch: 2/391\n",
      "rho:  0.75\n",
      "Batch: 3/391\n",
      "rho:  0.8\n",
      "Batch: 4/391\n",
      "rho:  0.8333333333333334\n",
      "Batch: 5/391\n",
      "rho:  0.8571428571428572\n",
      "Batch: 6/391\n",
      "rho:  0.875\n",
      "Batch: 7/391\n",
      "rho:  0.8888888888888888\n",
      "Batch: 8/391\n",
      "rho:  0.9\n",
      "Batch: 9/391\n",
      "rho:  0.9090909090909091\n",
      "Batch: 10/391\n",
      "rho:  0.9166666666666666\n",
      "Batch: 11/391\n",
      "rho:  0.9230769230769231\n",
      "Batch: 12/391\n",
      "rho:  0.9285714285714286\n",
      "Batch: 13/391\n",
      "rho:  0.9333333333333333\n",
      "Batch: 14/391\n",
      "rho:  0.9375\n",
      "Batch: 15/391\n",
      "rho:  0.9411764705882353\n",
      "Batch: 16/391\n",
      "rho:  0.9444444444444444\n",
      "Batch: 17/391\n",
      "rho:  0.9473684210526316\n",
      "Batch: 18/391\n",
      "rho:  0.95\n",
      "Batch: 19/391\n",
      "rho:  0.9523809523809523\n",
      "Batch: 20/391\n",
      "rho:  0.9545454545454546\n",
      "Batch: 21/391\n",
      "rho:  0.9565217391304348\n",
      "Batch: 22/391\n",
      "rho:  0.9583333333333334\n",
      "Batch: 23/391\n",
      "rho:  0.96\n",
      "Batch: 24/391\n",
      "rho:  0.9615384615384616\n",
      "Batch: 25/391\n",
      "rho:  0.962962962962963\n",
      "Batch: 26/391\n",
      "rho:  0.9642857142857143\n",
      "Batch: 27/391\n",
      "rho:  0.9655172413793104\n",
      "Batch: 28/391\n",
      "rho:  0.9666666666666667\n",
      "Batch: 29/391\n",
      "rho:  0.967741935483871\n",
      "Batch: 30/391\n",
      "rho:  0.96875\n",
      "Batch: 31/391\n",
      "rho:  0.9696969696969697\n",
      "Batch: 32/391\n",
      "rho:  0.9705882352941176\n",
      "Batch: 33/391\n",
      "rho:  0.9714285714285714\n",
      "Batch: 34/391\n",
      "rho:  0.9722222222222222\n",
      "Batch: 35/391\n",
      "rho:  0.972972972972973\n",
      "Batch: 36/391\n",
      "rho:  0.9736842105263158\n",
      "Batch: 37/391\n",
      "rho:  0.9743589743589743\n",
      "Batch: 38/391\n",
      "rho:  0.975\n",
      "Batch: 39/391\n",
      "rho:  0.975609756097561\n",
      "Batch: 40/391\n",
      "rho:  0.9761904761904762\n",
      "Batch: 41/391\n",
      "rho:  0.9767441860465116\n",
      "Batch: 42/391\n",
      "rho:  0.9772727272727273\n",
      "Batch: 43/391\n",
      "rho:  0.9777777777777777\n",
      "Batch: 44/391\n",
      "rho:  0.9782608695652174\n",
      "Batch: 45/391\n",
      "rho:  0.9787234042553191\n",
      "Batch: 46/391\n",
      "rho:  0.9791666666666666\n",
      "Batch: 47/391\n",
      "rho:  0.9795918367346939\n",
      "Batch: 48/391\n",
      "rho:  0.98\n",
      "Batch: 49/391\n",
      "rho:  0.9803921568627451\n",
      "Batch: 50/391\n",
      "rho:  0.9807692307692307\n",
      "Batch: 51/391\n",
      "rho:  0.9811320754716981\n",
      "Batch: 52/391\n",
      "rho:  0.9814814814814815\n",
      "Batch: 53/391\n",
      "rho:  0.9818181818181818\n",
      "Batch: 54/391\n",
      "rho:  0.9821428571428571\n",
      "Batch: 55/391\n",
      "rho:  0.9824561403508771\n",
      "Batch: 56/391\n",
      "rho:  0.9827586206896551\n",
      "Batch: 57/391\n",
      "rho:  0.9830508474576272\n",
      "Batch: 58/391\n",
      "rho:  0.9833333333333333\n",
      "Batch: 59/391\n",
      "rho:  0.9836065573770492\n",
      "Batch: 60/391\n",
      "rho:  0.9838709677419355\n",
      "Batch: 61/391\n",
      "rho:  0.9841269841269842\n",
      "Batch: 62/391\n",
      "rho:  0.984375\n",
      "Batch: 63/391\n",
      "rho:  0.9846153846153847\n",
      "Batch: 64/391\n",
      "rho:  0.9848484848484849\n",
      "Batch: 65/391\n",
      "rho:  0.9850746268656716\n",
      "Batch: 66/391\n",
      "rho:  0.9852941176470589\n",
      "Batch: 67/391\n",
      "rho:  0.9855072463768116\n",
      "Batch: 68/391\n",
      "rho:  0.9857142857142858\n",
      "Batch: 69/391\n",
      "rho:  0.9859154929577465\n",
      "Batch: 70/391\n",
      "rho:  0.9861111111111112\n",
      "Batch: 71/391\n",
      "rho:  0.9863013698630136\n",
      "Batch: 72/391\n",
      "rho:  0.9864864864864865\n",
      "Batch: 73/391\n",
      "rho:  0.9866666666666667\n",
      "Batch: 74/391\n",
      "rho:  0.9868421052631579\n",
      "Batch: 75/391\n",
      "rho:  0.987012987012987\n",
      "Batch: 76/391\n",
      "rho:  0.9871794871794872\n",
      "Batch: 77/391\n",
      "rho:  0.9873417721518988\n",
      "Batch: 78/391\n",
      "rho:  0.9875\n",
      "Batch: 79/391\n",
      "rho:  0.9876543209876543\n",
      "Batch: 80/391\n",
      "rho:  0.9878048780487805\n",
      "Batch: 81/391\n",
      "rho:  0.9879518072289156\n",
      "Batch: 82/391\n",
      "rho:  0.9880952380952381\n",
      "Batch: 83/391\n",
      "rho:  0.9882352941176471\n",
      "Batch: 84/391\n",
      "rho:  0.9883720930232558\n",
      "Batch: 85/391\n",
      "rho:  0.9885057471264368\n",
      "Batch: 86/391\n",
      "rho:  0.9886363636363636\n",
      "Batch: 87/391\n",
      "rho:  0.9887640449438202\n",
      "Batch: 88/391\n",
      "rho:  0.9888888888888889\n",
      "Batch: 89/391\n",
      "rho:  0.989010989010989\n",
      "Batch: 90/391\n",
      "rho:  0.9891304347826086\n",
      "Batch: 91/391\n",
      "rho:  0.989247311827957\n",
      "Batch: 92/391\n",
      "rho:  0.9893617021276596\n",
      "Batch: 93/391\n",
      "rho:  0.9894736842105263\n",
      "Batch: 94/391\n",
      "rho:  0.9895833333333334\n",
      "Batch: 95/391\n",
      "rho:  0.9896907216494846\n",
      "Batch: 96/391\n",
      "rho:  0.9897959183673469\n",
      "Batch: 97/391\n",
      "rho:  0.98989898989899\n",
      "Batch: 98/391\n",
      "rho:  0.99\n",
      "Batch: 99/391\n",
      "rho:  0.9900990099009901\n",
      "Batch: 100/391\n",
      "rho:  0.9901960784313726\n",
      "Batch: 101/391\n",
      "rho:  0.9902912621359223\n",
      "Batch: 102/391\n",
      "rho:  0.9903846153846154\n",
      "Batch: 103/391\n",
      "rho:  0.9904761904761905\n",
      "Batch: 104/391\n",
      "rho:  0.9905660377358491\n",
      "Batch: 105/391\n",
      "rho:  0.9906542056074766\n",
      "Batch: 106/391\n",
      "rho:  0.9907407407407407\n",
      "Batch: 107/391\n",
      "rho:  0.9908256880733946\n",
      "Batch: 108/391\n",
      "rho:  0.990909090909091\n",
      "Batch: 109/391\n",
      "rho:  0.990990990990991\n",
      "Batch: 110/391\n",
      "rho:  0.9910714285714286\n",
      "Batch: 111/391\n",
      "rho:  0.9911504424778761\n",
      "Batch: 112/391\n",
      "rho:  0.9912280701754386\n",
      "Batch: 113/391\n",
      "rho:  0.991304347826087\n",
      "Batch: 114/391\n",
      "rho:  0.9913793103448276\n",
      "Batch: 115/391\n",
      "rho:  0.9914529914529915\n",
      "Batch: 116/391\n",
      "rho:  0.9915254237288136\n",
      "Batch: 117/391\n",
      "rho:  0.9915966386554622\n",
      "Batch: 118/391\n",
      "rho:  0.9916666666666667\n",
      "Batch: 119/391\n",
      "rho:  0.9917355371900827\n",
      "Batch: 120/391\n",
      "rho:  0.9918032786885246\n",
      "Batch: 121/391\n",
      "rho:  0.991869918699187\n",
      "Batch: 122/391\n",
      "rho:  0.9919354838709677\n",
      "Batch: 123/391\n",
      "rho:  0.992\n",
      "Batch: 124/391\n",
      "rho:  0.9920634920634921\n",
      "Batch: 125/391\n",
      "rho:  0.9921259842519685\n",
      "Batch: 126/391\n",
      "rho:  0.9921875\n",
      "Batch: 127/391\n",
      "rho:  0.9922480620155039\n",
      "Batch: 128/391\n",
      "rho:  0.9923076923076923\n",
      "Batch: 129/391\n",
      "rho:  0.9923664122137404\n",
      "Batch: 130/391\n",
      "rho:  0.9924242424242424\n",
      "Batch: 131/391\n",
      "rho:  0.9924812030075187\n",
      "Batch: 132/391\n",
      "rho:  0.9925373134328358\n",
      "Batch: 133/391\n",
      "rho:  0.9925925925925926\n",
      "Batch: 134/391\n",
      "rho:  0.9926470588235294\n",
      "Batch: 135/391\n",
      "rho:  0.9927007299270073\n",
      "Batch: 136/391\n",
      "rho:  0.9927536231884058\n",
      "Batch: 137/391\n",
      "rho:  0.9928057553956835\n",
      "Batch: 138/391\n",
      "rho:  0.9928571428571429\n",
      "Batch: 139/391\n",
      "rho:  0.9929078014184397\n",
      "Batch: 140/391\n",
      "rho:  0.9929577464788732\n",
      "Batch: 141/391\n",
      "rho:  0.993006993006993\n",
      "Batch: 142/391\n",
      "rho:  0.9930555555555556\n",
      "Batch: 143/391\n",
      "rho:  0.993103448275862\n",
      "Batch: 144/391\n",
      "rho:  0.9931506849315068\n",
      "Batch: 145/391\n",
      "rho:  0.9931972789115646\n",
      "Batch: 146/391\n",
      "rho:  0.9932432432432432\n",
      "Batch: 147/391\n",
      "rho:  0.9932885906040269\n",
      "Batch: 148/391\n",
      "rho:  0.9933333333333333\n",
      "Batch: 149/391\n",
      "rho:  0.9933774834437086\n",
      "Batch: 150/391\n",
      "rho:  0.993421052631579\n",
      "Batch: 151/391\n",
      "rho:  0.9934640522875817\n",
      "Batch: 152/391\n",
      "rho:  0.9935064935064936\n",
      "Batch: 153/391\n",
      "rho:  0.9935483870967742\n",
      "Batch: 154/391\n",
      "rho:  0.9935897435897436\n",
      "Batch: 155/391\n",
      "rho:  0.9936305732484076\n",
      "Batch: 156/391\n",
      "rho:  0.9936708860759493\n",
      "Batch: 157/391\n",
      "rho:  0.9937106918238994\n",
      "Batch: 158/391\n",
      "rho:  0.99375\n",
      "Batch: 159/391\n",
      "rho:  0.9937888198757764\n",
      "Batch: 160/391\n",
      "rho:  0.9938271604938271\n",
      "Batch: 161/391\n",
      "rho:  0.9938650306748467\n",
      "Batch: 162/391\n",
      "rho:  0.9939024390243902\n",
      "Batch: 163/391\n",
      "rho:  0.9939393939393939\n",
      "Batch: 164/391\n",
      "rho:  0.9939759036144579\n",
      "Batch: 165/391\n",
      "rho:  0.9940119760479041\n",
      "Batch: 166/391\n",
      "rho:  0.9940476190476191\n",
      "Batch: 167/391\n",
      "rho:  0.9940828402366864\n",
      "Batch: 168/391\n",
      "rho:  0.9941176470588236\n",
      "Batch: 169/391\n",
      "rho:  0.9941520467836258\n",
      "Batch: 170/391\n",
      "rho:  0.9941860465116279\n",
      "Batch: 171/391\n",
      "rho:  0.9942196531791907\n",
      "Batch: 172/391\n",
      "rho:  0.9942528735632183\n",
      "Batch: 173/391\n",
      "rho:  0.9942857142857143\n",
      "Batch: 174/391\n",
      "rho:  0.9943181818181818\n",
      "Batch: 175/391\n",
      "rho:  0.9943502824858758\n",
      "Batch: 176/391\n",
      "rho:  0.9943820224719101\n",
      "Batch: 177/391\n",
      "rho:  0.994413407821229\n",
      "Batch: 178/391\n",
      "rho:  0.9944444444444445\n",
      "Batch: 179/391\n",
      "rho:  0.994475138121547\n",
      "Batch: 180/391\n",
      "rho:  0.9945054945054945\n",
      "Batch: 181/391\n",
      "rho:  0.994535519125683\n",
      "Batch: 182/391\n",
      "rho:  0.9945652173913043\n",
      "Batch: 183/391\n",
      "rho:  0.9945945945945946\n",
      "Batch: 184/391\n",
      "rho:  0.9946236559139785\n",
      "Batch: 185/391\n",
      "rho:  0.9946524064171123\n",
      "Batch: 186/391\n",
      "rho:  0.9946808510638298\n",
      "Batch: 187/391\n",
      "rho:  0.9947089947089947\n",
      "Batch: 188/391\n",
      "rho:  0.9947368421052631\n",
      "Batch: 189/391\n",
      "rho:  0.9947643979057592\n",
      "Batch: 190/391\n",
      "rho:  0.9947916666666666\n",
      "Batch: 191/391\n",
      "rho:  0.9948186528497409\n",
      "Batch: 192/391\n",
      "rho:  0.9948453608247423\n",
      "Batch: 193/391\n",
      "rho:  0.9948717948717949\n",
      "Batch: 194/391\n",
      "rho:  0.9948979591836735\n",
      "Batch: 195/391\n",
      "rho:  0.9949238578680203\n",
      "Batch: 196/391\n",
      "rho:  0.9949494949494949\n",
      "Batch: 197/391\n",
      "rho:  0.9949748743718593\n",
      "Batch: 198/391\n",
      "rho:  0.995\n",
      "Batch: 199/391\n",
      "rho:  0.9950248756218906\n",
      "Batch: 200/391\n",
      "rho:  0.995049504950495\n",
      "Batch: 201/391\n",
      "rho:  0.9950738916256158\n",
      "Batch: 202/391\n",
      "rho:  0.9950980392156863\n",
      "Batch: 203/391\n",
      "rho:  0.9951219512195122\n",
      "Batch: 204/391\n",
      "rho:  0.9951456310679612\n",
      "Batch: 205/391\n",
      "rho:  0.9951690821256038\n",
      "Batch: 206/391\n",
      "rho:  0.9951923076923077\n",
      "Batch: 207/391\n",
      "rho:  0.9952153110047847\n",
      "Batch: 208/391\n",
      "rho:  0.9952380952380953\n",
      "Batch: 209/391\n",
      "rho:  0.995260663507109\n",
      "Batch: 210/391\n",
      "rho:  0.9952830188679245\n",
      "Batch: 211/391\n",
      "rho:  0.9953051643192489\n",
      "Batch: 212/391\n",
      "rho:  0.9953271028037384\n",
      "Batch: 213/391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho:  0.9953488372093023\n",
      "Batch: 214/391\n",
      "rho:  0.9953703703703703\n",
      "Batch: 215/391\n",
      "rho:  0.9953917050691244\n",
      "Batch: 216/391\n",
      "rho:  0.9954128440366973\n",
      "Batch: 217/391\n",
      "rho:  0.995433789954338\n",
      "Batch: 218/391\n",
      "rho:  0.9954545454545455\n",
      "Batch: 219/391\n",
      "rho:  0.995475113122172\n",
      "Batch: 220/391\n",
      "rho:  0.9954954954954955\n",
      "Batch: 221/391\n",
      "rho:  0.9955156950672646\n",
      "Batch: 222/391\n",
      "rho:  0.9955357142857143\n",
      "Batch: 223/391\n",
      "rho:  0.9955555555555555\n",
      "Batch: 224/391\n",
      "rho:  0.995575221238938\n",
      "Batch: 225/391\n",
      "rho:  0.9955947136563876\n",
      "Batch: 226/391\n",
      "rho:  0.9956140350877193\n",
      "Batch: 227/391\n",
      "rho:  0.9956331877729258\n",
      "Batch: 228/391\n",
      "rho:  0.9956521739130435\n",
      "Batch: 229/391\n",
      "rho:  0.9956709956709957\n",
      "Batch: 230/391\n",
      "rho:  0.9956896551724138\n",
      "Batch: 231/391\n",
      "rho:  0.9957081545064378\n",
      "Batch: 232/391\n",
      "rho:  0.9957264957264957\n",
      "Batch: 233/391\n",
      "rho:  0.9957446808510638\n",
      "Batch: 234/391\n",
      "rho:  0.9957627118644068\n",
      "Batch: 235/391\n",
      "rho:  0.9957805907172996\n",
      "Batch: 236/391\n",
      "rho:  0.9957983193277311\n",
      "Batch: 237/391\n",
      "rho:  0.99581589958159\n",
      "Batch: 238/391\n",
      "rho:  0.9958333333333333\n",
      "Batch: 239/391\n",
      "rho:  0.995850622406639\n",
      "Batch: 240/391\n",
      "rho:  0.9958677685950413\n",
      "Batch: 241/391\n",
      "rho:  0.9958847736625515\n",
      "Batch: 242/391\n",
      "rho:  0.9959016393442623\n",
      "Batch: 243/391\n",
      "rho:  0.9959183673469387\n",
      "Batch: 244/391\n",
      "rho:  0.9959349593495935\n",
      "Batch: 245/391\n",
      "rho:  0.9959514170040485\n",
      "Batch: 246/391\n",
      "rho:  0.9959677419354839\n",
      "Batch: 247/391\n",
      "rho:  0.9959839357429718\n",
      "Batch: 248/391\n",
      "rho:  0.996\n",
      "Batch: 249/391\n",
      "rho:  0.9960159362549801\n",
      "Batch: 250/391\n",
      "rho:  0.996031746031746\n",
      "Batch: 251/391\n",
      "rho:  0.9960474308300395\n",
      "Batch: 252/391\n",
      "rho:  0.9960629921259843\n",
      "Batch: 253/391\n",
      "rho:  0.996078431372549\n",
      "Batch: 254/391\n",
      "rho:  0.99609375\n",
      "Batch: 255/391\n",
      "rho:  0.9961089494163424\n",
      "Batch: 256/391\n",
      "rho:  0.9961240310077519\n",
      "Batch: 257/391\n",
      "rho:  0.9961389961389961\n",
      "Batch: 258/391\n",
      "rho:  0.9961538461538462\n",
      "Batch: 259/391\n",
      "rho:  0.9961685823754789\n",
      "Batch: 260/391\n",
      "rho:  0.9961832061068703\n",
      "Batch: 261/391\n",
      "rho:  0.9961977186311787\n",
      "Batch: 262/391\n",
      "rho:  0.9962121212121212\n",
      "Batch: 263/391\n",
      "rho:  0.9962264150943396\n",
      "Batch: 264/391\n",
      "rho:  0.9962406015037594\n",
      "Batch: 265/391\n",
      "rho:  0.9962546816479401\n",
      "Batch: 266/391\n",
      "rho:  0.996268656716418\n",
      "Batch: 267/391\n",
      "rho:  0.9962825278810409\n",
      "Batch: 268/391\n",
      "rho:  0.9962962962962963\n",
      "Batch: 269/391\n",
      "rho:  0.996309963099631\n",
      "Batch: 270/391\n",
      "rho:  0.9963235294117647\n",
      "Batch: 271/391\n",
      "rho:  0.9963369963369964\n",
      "Batch: 272/391\n",
      "rho:  0.9963503649635036\n",
      "Batch: 273/391\n",
      "rho:  0.9963636363636363\n",
      "Batch: 274/391\n",
      "rho:  0.9963768115942029\n",
      "Batch: 275/391\n",
      "rho:  0.9963898916967509\n",
      "Batch: 276/391\n",
      "rho:  0.9964028776978417\n",
      "Batch: 277/391\n",
      "rho:  0.996415770609319\n",
      "Batch: 278/391\n",
      "rho:  0.9964285714285714\n",
      "Batch: 279/391\n",
      "rho:  0.99644128113879\n",
      "Batch: 280/391\n",
      "rho:  0.9964539007092199\n",
      "Batch: 281/391\n",
      "rho:  0.9964664310954063\n",
      "Batch: 282/391\n",
      "rho:  0.9964788732394366\n",
      "Batch: 283/391\n",
      "rho:  0.9964912280701754\n",
      "Batch: 284/391\n",
      "rho:  0.9965034965034965\n",
      "Batch: 285/391\n",
      "rho:  0.9965156794425087\n",
      "Batch: 286/391\n",
      "rho:  0.9965277777777778\n",
      "Batch: 287/391\n",
      "rho:  0.9965397923875432\n",
      "Batch: 288/391\n",
      "rho:  0.996551724137931\n",
      "Batch: 289/391\n",
      "rho:  0.9965635738831615\n",
      "Batch: 290/391\n",
      "rho:  0.9965753424657534\n",
      "Batch: 291/391\n",
      "rho:  0.9965870307167235\n",
      "Batch: 292/391\n",
      "rho:  0.9965986394557823\n",
      "Batch: 293/391\n",
      "rho:  0.9966101694915255\n",
      "Batch: 294/391\n",
      "rho:  0.9966216216216216\n",
      "Batch: 295/391\n",
      "rho:  0.9966329966329966\n",
      "Batch: 296/391\n",
      "rho:  0.9966442953020134\n",
      "Batch: 297/391\n",
      "rho:  0.9966555183946488\n",
      "Batch: 298/391\n",
      "rho:  0.9966666666666667\n",
      "Batch: 299/391\n",
      "rho:  0.9966777408637874\n",
      "Batch: 300/391\n",
      "rho:  0.9966887417218543\n",
      "Batch: 301/391\n",
      "rho:  0.9966996699669967\n",
      "Batch: 302/391\n",
      "rho:  0.9967105263157895\n",
      "Batch: 303/391\n",
      "rho:  0.9967213114754099\n",
      "Batch: 304/391\n",
      "rho:  0.9967320261437909\n",
      "Batch: 305/391\n",
      "rho:  0.996742671009772\n",
      "Batch: 306/391\n",
      "rho:  0.9967532467532467\n",
      "Batch: 307/391\n",
      "rho:  0.9967637540453075\n",
      "Batch: 308/391\n",
      "rho:  0.9967741935483871\n",
      "Batch: 309/391\n",
      "rho:  0.9967845659163987\n",
      "Batch: 310/391\n",
      "rho:  0.9967948717948718\n",
      "Batch: 311/391\n",
      "rho:  0.9968051118210862\n",
      "Batch: 312/391\n",
      "rho:  0.9968152866242038\n",
      "Batch: 313/391\n",
      "rho:  0.9968253968253968\n",
      "Batch: 314/391\n",
      "rho:  0.9968354430379747\n",
      "Batch: 315/391\n",
      "rho:  0.9968454258675079\n",
      "Batch: 316/391\n",
      "rho:  0.9968553459119497\n",
      "Batch: 317/391\n",
      "rho:  0.9968652037617555\n",
      "Batch: 318/391\n",
      "rho:  0.996875\n",
      "Batch: 319/391\n",
      "rho:  0.9968847352024922\n",
      "Batch: 320/391\n",
      "rho:  0.9968944099378882\n",
      "Batch: 321/391\n",
      "rho:  0.9969040247678018\n",
      "Batch: 322/391\n",
      "rho:  0.9969135802469136\n",
      "Batch: 323/391\n",
      "rho:  0.9969230769230769\n",
      "Batch: 324/391\n",
      "rho:  0.9969325153374233\n",
      "Batch: 325/391\n",
      "rho:  0.9969418960244648\n",
      "Batch: 326/391\n",
      "rho:  0.9969512195121951\n",
      "Batch: 327/391\n",
      "rho:  0.9969604863221885\n",
      "Batch: 328/391\n",
      "rho:  0.996969696969697\n",
      "Batch: 329/391\n",
      "rho:  0.9969788519637462\n",
      "Batch: 330/391\n",
      "rho:  0.9969879518072289\n",
      "Batch: 331/391\n",
      "rho:  0.996996996996997\n",
      "Batch: 332/391\n",
      "rho:  0.9970059880239521\n",
      "Batch: 333/391\n",
      "rho:  0.9970149253731343\n",
      "Batch: 334/391\n",
      "rho:  0.9970238095238095\n",
      "Batch: 335/391\n",
      "rho:  0.9970326409495549\n",
      "Batch: 336/391\n",
      "rho:  0.9970414201183432\n",
      "Batch: 337/391\n",
      "rho:  0.9970501474926253\n",
      "Batch: 338/391\n",
      "rho:  0.9970588235294118\n",
      "Batch: 339/391\n",
      "rho:  0.9970674486803519\n",
      "Batch: 340/391\n",
      "rho:  0.9970760233918129\n",
      "Batch: 341/391\n",
      "rho:  0.9970845481049563\n",
      "Batch: 342/391\n",
      "rho:  0.997093023255814\n",
      "Batch: 343/391\n",
      "rho:  0.9971014492753624\n",
      "Batch: 344/391\n",
      "rho:  0.9971098265895953\n",
      "Batch: 345/391\n",
      "rho:  0.9971181556195965\n",
      "Batch: 346/391\n",
      "rho:  0.9971264367816092\n",
      "Batch: 347/391\n",
      "rho:  0.997134670487106\n",
      "Batch: 348/391\n",
      "rho:  0.9971428571428571\n",
      "Batch: 349/391\n",
      "rho:  0.9971509971509972\n",
      "Batch: 350/391\n",
      "rho:  0.9971590909090909\n",
      "Batch: 351/391\n",
      "rho:  0.9971671388101983\n",
      "Batch: 352/391\n",
      "rho:  0.9971751412429378\n",
      "Batch: 353/391\n",
      "rho:  0.9971830985915493\n",
      "Batch: 354/391\n",
      "rho:  0.9971910112359551\n",
      "Batch: 355/391\n",
      "rho:  0.9971988795518207\n",
      "Batch: 356/391\n",
      "rho:  0.9972067039106145\n",
      "Batch: 357/391\n",
      "rho:  0.9972144846796658\n",
      "Batch: 358/391\n",
      "rho:  0.9972222222222222\n",
      "Batch: 359/391\n",
      "rho:  0.997229916897507\n",
      "Batch: 360/391\n",
      "rho:  0.9972375690607734\n",
      "Batch: 361/391\n",
      "rho:  0.9972451790633609\n",
      "Batch: 362/391\n",
      "rho:  0.9972527472527473\n",
      "Batch: 363/391\n",
      "rho:  0.9972602739726028\n",
      "Batch: 364/391\n",
      "rho:  0.9972677595628415\n",
      "Batch: 365/391\n",
      "rho:  0.997275204359673\n",
      "Batch: 366/391\n",
      "rho:  0.9972826086956522\n",
      "Batch: 367/391\n",
      "rho:  0.997289972899729\n",
      "Batch: 368/391\n",
      "rho:  0.9972972972972973\n",
      "Batch: 369/391\n",
      "rho:  0.9973045822102425\n",
      "Batch: 370/391\n",
      "rho:  0.9973118279569892\n",
      "Batch: 371/391\n",
      "rho:  0.9973190348525469\n",
      "Batch: 372/391\n",
      "rho:  0.9973262032085561\n",
      "Batch: 373/391\n",
      "rho:  0.9973333333333333\n",
      "Batch: 374/391\n",
      "rho:  0.9973404255319149\n",
      "Batch: 375/391\n",
      "rho:  0.9973474801061007\n",
      "Batch: 376/391\n",
      "rho:  0.9973544973544973\n",
      "Batch: 377/391\n",
      "rho:  0.9973614775725593\n",
      "Batch: 378/391\n",
      "rho:  0.9973684210526316\n",
      "Batch: 379/391\n",
      "rho:  0.9973753280839895\n",
      "Batch: 380/391\n",
      "rho:  0.9973821989528796\n",
      "Batch: 381/391\n",
      "rho:  0.9973890339425587\n",
      "Batch: 382/391\n",
      "rho:  0.9973958333333334\n",
      "Batch: 383/391\n",
      "rho:  0.9974025974025974\n",
      "Batch: 384/391\n",
      "rho:  0.9974093264248705\n",
      "Batch: 385/391\n",
      "rho:  0.9974160206718347\n",
      "Batch: 386/391\n",
      "rho:  0.9974226804123711\n",
      "Batch: 387/391\n",
      "rho:  0.9974293059125964\n",
      "Batch: 388/391\n",
      "rho:  0.9974358974358974\n",
      "Batch: 389/391\n",
      "rho:  0.9974424552429667\n",
      "Batch: 390/391\n",
      "M_W_post size:  torch.Size([512, 10])\n",
      "M_b_post size:  torch.Size([10])\n",
      "C_W_post size:  torch.Size([10, 512])\n",
      "C_b_post size:  torch.Size([10])\n",
      "preparing Gaussians took 28.942354202270508 seconds which is 0.4823725700378418 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D = Diag_second_order(model=CIFAR10_model,\n",
    "                                                                   train_loader=CIFAR10_train_loader,\n",
    "                                                                   var0 = 1e-2, #1e-2\n",
    "                                                                   device=device)\n",
    "t1 = time.time()\n",
    "time_gaussian = t1-t0\n",
    "print(\"preparing Gaussians took {} seconds which is {} minutes\".format(time_gaussian, time_gaussian/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing Gaussians took 29.08268094062805 seconds which is 0.48471134901046753 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eJsYd6Aec_Ke"
   },
   "outputs": [],
   "source": [
    "targets_CIFAR10 = CIFAR10_testset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZ85ABdwHSrC"
   },
   "outputs": [],
   "source": [
    "#number of samples to draw from the Gaussian\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UqikIW_Cc_Lb"
   },
   "source": [
    "# Diagonal estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_diagonal_sampling(model, test_loader, M_W_post, M_b_post, C_W_post, C_b_post, n_samples, verbose=False, timing=False, cuda=True):\n",
    "    py = []\n",
    "    max_len = len(test_loader)\n",
    "    if timing:\n",
    "        time_sum_fw = 0\n",
    "        time_sum_sampling = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        t0_fw = time.process_time()\n",
    "        phi = model.phi(x).detach()\n",
    "\n",
    "        mu, Sigma = get_Gaussian_output(phi, M_W_post, M_b_post, C_W_post, C_b_post)\n",
    "        #mu, Sigma = mu.cpu(), Sigma.cpu()\n",
    "        t1_fw = time.time_process()\n",
    "\n",
    "        post_pred = MultivariateNormal(mu, Sigma)\n",
    "\n",
    "        # MC-integral\n",
    "        py_ = 0\n",
    "        \n",
    "        t0_sampling = time.process_time()\n",
    "        for _ in range(n_samples):\n",
    "            f_s = post_pred.rsample()\n",
    "            py_ += torch.softmax(f_s, 1).detach()\n",
    "\n",
    "        py_ /= n_samples\n",
    "        py_ = py_.detach()\n",
    "        t1_sampling = time.process_time()\n",
    "\n",
    "        py.append(py_)\n",
    "        \n",
    "        if timing:\n",
    "            time_sum_fw += (t1_fw - t0_fw)\n",
    "            time_sum_lb += (t1_sampling - t0_sampling)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "            \n",
    "    if timing:\n",
    "        print(\"total time used for forward pass: {:.05f}\".format(time_sum_fw))\n",
    "        print(\"total time used for sampling: {:.05f}\".format(time_sum_sampling))\n",
    "\n",
    "    return torch.cat(py, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 452527,
     "status": "ok",
     "timestamp": 1588243526367,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "e38KQHHAc_Lc",
    "outputId": "df598af1-8a3e-4d38-8130-b399b79eaf0f"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'time' has no attribute 'time_process'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2625/1270103540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCIFAR10_test_in_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_diagonal_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCIFAR10_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCIFAR10_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_W_post_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_b_post_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_W_post_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_b_post_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2625/3797974915.py\u001b[0m in \u001b[0;36mpredict_diagonal_sampling\u001b[0;34m(model, test_loader, M_W_post, M_b_post, C_W_post, C_b_post, n_samples, verbose, timing, cuda)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mt0_fw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'time' has no attribute 'time_process'"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_D = predict_diagonal_sampling(CIFAR10_model, CIFAR10_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, n_samples=num_samples, cuda=cuda_status, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward pass timing: 0.448 with std. 0.004\n",
      "mc 1000 timing: 8.183 with std. 0.080\n",
      "mc 100 timing: 0.867 with std. 0.004\n",
      "mc 10 timing: 0.117 with std. 0.001\n",
      "percentage forward: 0.052 vs mc 1000: 0.948\n",
      "percentage forward: 0.341 vs mc 100: 0.659\n",
      "percentage forward: 0.793 vs mc 10: 0.207\n"
     ]
    }
   ],
   "source": [
    "#timings for forward pass vs sampling as presented in the paper\n",
    "\n",
    "fw_pass = np.array([0.4554176330566406, 0.44563722610473633, 0.44574522972106934, 0.44403839111328125, 0.44765353202819824])\n",
    "mc_1000 = np.array([8.315938234329224, 8.18410873413086, 8.117920637130737, 8.08596658706665, 8.212565183639526])\n",
    "mc_100 =  np.array([0.8649516105651855, 0.8614475727081299, 0.8721733093261719, 0.8692750930786133, 0.8676304817199707])\n",
    "mc_10 =   np.array([0.11789608001708984, 0.11717033386230469, 0.11659884452819824, 0.11590909957885742, 0.11641597747802734])\n",
    "\n",
    "print(\"forward pass timing: {:.03f} with std. {:.03f}\".format(np.mean(fw_pass), np.std(fw_pass)))\n",
    "print(\"mc 1000 timing: {:.03f} with std. {:.03f}\".format(np.mean(mc_1000), np.std(mc_1000)))\n",
    "print(\"mc 100 timing: {:.03f} with std. {:.03f}\".format(np.mean(mc_100), np.std(mc_100)))\n",
    "print(\"mc 10 timing: {:.03f} with std. {:.03f}\".format(np.mean(mc_10), np.std(mc_10)))\n",
    "\n",
    "fw_mc1000 = np.mean(fw_pass) + np.mean(mc_1000)\n",
    "fw_mc100 = np.mean(fw_pass) + np.mean(mc_100)\n",
    "fw_mc10 = np.mean(fw_pass) + np.mean(mc_10)\n",
    "print(\"percentage forward: {:.03f} vs mc 1000: {:.03f}\".format(np.mean(fw_pass)/fw_mc1000, np.mean(mc_1000)/fw_mc1000))\n",
    "print(\"percentage forward: {:.03f} vs mc 100: {:.03f}\".format(np.mean(fw_pass)/fw_mc100, np.mean(mc_100)/fw_mc100))\n",
    "print(\"percentage forward: {:.03f} vs mc 10: {:.03f}\".format(np.mean(fw_pass)/fw_mc10, np.mean(mc_10)/fw_mc10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace Bridge estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551516,
     "status": "ok",
     "timestamp": 1588243625465,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "wdwRD0V8c_M2",
    "outputId": "997ab5e3-7a4c-44a5-9b05-42dd69cd879b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for forward pass: 0.86208\n",
      "total time used for Laplace Bridge: 0.03456\n",
      "total time used for forward pass: 0.70963\n",
      "total time used for Laplace Bridge: 0.02774\n",
      "total time used for forward pass: 1.90970\n",
      "total time used for Laplace Bridge: 0.07455\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_LB = predict_LB(CIFAR10_model, CIFAR10_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, verbose=False, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_LB = predict_LB(CIFAR10_model, CIFAR100_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_LB = predict_LB(CIFAR10_model, SVHN_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timing for Laplace Bridge: 0.014 with std 0.000\n",
      "percentage forward: 0.970 vs lb: 0.030\n"
     ]
    }
   ],
   "source": [
    "# timings for forward pass vs Laplace Bridge as presented in the main paper\n",
    "time_lb = np.array([0.01397, 0.01397, 0.01405, 0.01389, 0.01402])\n",
    "\n",
    "print(\"timing for Laplace Bridge: {:.03f} with std {:.03f}\".format(np.mean(time_lb), np.std(time_lb)))\n",
    "\n",
    "fw_lb = np.mean(fw_pass) + np.mean(time_lb)\n",
    "print(\"percentage forward: {:.03f} vs lb: {:.03f}\".format(np.mean(fw_pass)/fw_lb, np.mean(time_lb)/fw_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08wlLgMec_M9"
   },
   "outputs": [],
   "source": [
    "#normalize to get the MAP estimate (which is the mode) of the Dirichlet\n",
    "CIFAR10_test_in_LBn = CIFAR10_test_in_LB/CIFAR10_test_in_LB.sum(1).reshape(-1,1)\n",
    "CIFAR10_test_out_CIFAR100_LBn = CIFAR10_test_out_CIFAR100_LB/CIFAR10_test_out_CIFAR100_LB.sum(1).reshape(-1,1)\n",
    "CIFAR10_test_out_SVHN_LBn = CIFAR10_test_out_SVHN_LB/CIFAR10_test_out_SVHN_LB.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BVHBhW5c_ND"
   },
   "outputs": [],
   "source": [
    "acc_in_LB, prob_correct_in_LB, ent_in_LB, MMC_in_LB = get_in_dist_values(CIFAR10_test_in_LBn, targets_CIFAR10)\n",
    "acc_out_CIFAR100_LB, prob_correct_out_CIFAR100_LB, ent_out_CIFAR100_LB, MMC_out_CIFAR100_LB, auroc_out_CIFAR100_LB = get_out_dist_values(CIFAR10_test_in_LBn, CIFAR10_test_out_CIFAR100_LBn, targets_CIFAR100)\n",
    "acc_out_SVHN_LB, prob_correct_out_SVHN_LB, ent_out_SVHN_LB, MMC_out_SVHN_LB, auroc_out_SVHN_LB = get_out_dist_values(CIFAR10_test_in_LBn, CIFAR10_test_out_SVHN_LBn, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551492,
     "status": "ok",
     "timestamp": 1588243625468,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "NJx4wLw-c_NI",
    "outputId": "ac8ea466-91d6-4ef2-c365-29f677e78b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Laplace Bridge, CIFAR10] Accuracy: 0.954; average entropy: 0.140;     MMC: 0.966; Prob @ correct: 0.100\n",
      "[Out-CIFAR100, Laplace Bridge, CIFAR10] Accuracy: 0.009; Average entropy: 0.856;    MMC: 0.742; AUROC: 0.866; Prob @ correct: 0.100\n",
      "[Out-SVHN, Laplace Bridge, CIFAR10] Accuracy: 0.092; Average entropy: 1.177;    MMC: 0.647; AUROC: 0.934; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_LB, prob_correct_in_LB, ent_in_LB, MMC_in_LB, 'CIFAR10', 'Laplace Bridge')\n",
    "print_out_dist_values(acc_out_CIFAR100_LB, prob_correct_out_CIFAR100_LB, ent_out_CIFAR100_LB, MMC_out_CIFAR100_LB, auroc_out_CIFAR100_LB, 'CIFAR10', 'CIFAR100', 'Laplace Bridge')\n",
    "print_out_dist_values(acc_out_SVHN_LB, prob_correct_out_SVHN_LB, ent_out_SVHN_LB, MMC_out_SVHN_LB, auroc_out_SVHN_LB, 'CIFAR10', 'SVHN', 'Laplace Bridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551484,
     "status": "ok",
     "timestamp": 1588243625470,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "Pxhs0u1Dc_NP",
    "outputId": "8950588c-6ec8-4c55-dd96-dc7394590331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.017 with std 0.000\n",
      "Laplace Bridge time out CIFAR100: 0.016 with std 0.000\n",
      "Laplace Bridge time out notmnist: 0.041 with std 0.001\n",
      "accuracy: 0.954 with std 0.000\n",
      "MMC in: 0.966 with std 0.000\n",
      "MMC out CIFAR100: 0.742 with std 0.000\n",
      "MMC out SVHN: 0.647 with std 0.000\n",
      "AUROC out CIFAR100: 0.866 with std 0.000\n",
      "AUROC out SVHN: 0.934 with std 0.000\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge results as presented in the main paper\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.01661, 0.01664, 0.01658, 0.01646, 0.01734]\n",
    "time_lpb_out_CIFAR100 = [0.01575, 0.01610, 0.01561, 0.01592, 0.01615]\n",
    "time_lpb_out_SVHN = [0.04018, 0.04055, 0.04020, 0.04041, 0.04276]\n",
    "\n",
    "\n",
    "acc_in = [0.954, 0.954, 0.954, 0.954, 0.954]\n",
    "mmc_in = [0.966, 0.966, 0.966, 0.966, 0.966]\n",
    "mmc_out_CIFAR100 = [0.742, 0.742, 0.742, 0.742, 0.742]\n",
    "mmc_out_SVHN = [0.647, 0.647, 0.647, 0.647, 0.647]\n",
    "\n",
    "auroc_out_CIFAR100 = [0.866, 0.866, 0.866, 0.866, 0.866]\n",
    "auroc_out_SVHN = [0.934, 0.934, 0.934, 0.934, 0.934]\n",
    "\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "print(\"Laplace Bridge time out notmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58EZsST2E-2S"
   },
   "source": [
    "# Laplace Bridge KFAC estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 210531,
     "status": "ok",
     "timestamp": 1591121348617,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "4NXHOX4jE8jS",
    "outputId": "829dd220-7a22-4e12-ae34-09014a15199c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used for transform: 0.02535\n",
      "total time used for transform: 0.03012\n",
      "total time used for transform: 0.06282\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_LB_KFAC = predict_LB_KFAC(CIFAR10_model, CIFAR10_test_loader, M_W_post_K, M_b_post_K, U_post_K, V_post_K, B_post_K, cuda=cuda_status, verbose=False, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_LB_KFAC = predict_LB_KFAC(CIFAR10_model, CIFAR100_test_loader, M_W_post_K, M_b_post_K, U_post_K, V_post_K, B_post_K, cuda=cuda_status, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_LB_KFAC = predict_LB_KFAC(CIFAR10_model, SVHN_test_loader, M_W_post_K, M_b_post_K, U_post_K, V_post_K, B_post_K, cuda=cuda_status, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQjb5ulTFB7l"
   },
   "outputs": [],
   "source": [
    "#normalize to get the MAP estimate (which is the mode) of the Dirichlet\n",
    "CIFAR10_test_in_LB_KFACn = CIFAR10_test_in_LB_KFAC/CIFAR10_test_in_LB_KFAC.sum(1).reshape(-1,1)\n",
    "CIFAR10_test_out_CIFAR100_LB_KFACn = CIFAR10_test_out_CIFAR100_LB_KFAC/CIFAR10_test_out_CIFAR100_LB_KFAC.sum(1).reshape(-1,1)\n",
    "CIFAR10_test_out_SVHN_LB_KFACn = CIFAR10_test_out_SVHN_LB_KFAC/CIFAR10_test_out_SVHN_LB_KFAC.sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9wsn8byFCE5"
   },
   "outputs": [],
   "source": [
    "acc_in_LB_KFAC, prob_correct_in_LB_KFAC, ent_in_LB_KFAC, MMC_in_LB_KFAC = get_in_dist_values(CIFAR10_test_in_LB_KFACn, targets_CIFAR10)\n",
    "acc_out_CIFAR100_LB_KFAC, prob_correct_out_CIFAR100_LB_KFAC, ent_out_CIFAR100_LB_KFAC, MMC_out_CIFAR100_LB_KFAC, auroc_out_CIFAR100_LB_KFAC = get_out_dist_values(CIFAR10_test_in_LB_KFACn, CIFAR10_test_out_CIFAR100_LB_KFACn, targets_CIFAR100)\n",
    "acc_out_SVHN_LB_KFAC, prob_correct_out_SVHN_LB_KFAC, ent_out_SVHN_LB_KFAC, MMC_out_SVHN_LB_KFAC, auroc_out_SVHN_LB_KFAC = get_out_dist_values(CIFAR10_test_in_LB_KFACn, CIFAR10_test_out_SVHN_LB_KFACn, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 210501,
     "status": "ok",
     "timestamp": 1591121348625,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "mtWTHB0dFCMK",
    "outputId": "ba685fd8-78a0-4489-bd90-15d57f6e6c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Laplace Bridge, CIFAR10] Accuracy: 0.954; average entropy: 0.140;     MMC: 0.966; Prob @ correct: 0.100\n",
      "[Out-CIFAR100, Laplace Bridge, CIFAR10] Accuracy: 0.009; Average entropy: 0.855;    MMC: 0.742; AUROC: 0.866; Prob @ correct: 0.100\n",
      "[Out-SVHN, Laplace Bridge, CIFAR10] Accuracy: 0.093; Average entropy: 1.170;    MMC: 0.650; AUROC: 0.933; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_LB_KFAC, prob_correct_in_LB_KFAC, ent_in_LB_KFAC, MMC_in_LB_KFAC, 'CIFAR10', 'Laplace Bridge')\n",
    "print_out_dist_values(acc_out_CIFAR100_LB_KFAC, prob_correct_out_CIFAR100_LB_KFAC, ent_out_CIFAR100_LB_KFAC, MMC_out_CIFAR100_LB_KFAC, auroc_out_CIFAR100_LB_KFAC, 'CIFAR10', 'CIFAR100', 'Laplace Bridge')\n",
    "print_out_dist_values(acc_out_SVHN_LB_KFAC, prob_correct_out_SVHN_LB_KFAC, ent_out_SVHN_LB_KFAC, MMC_out_SVHN_LB_KFAC, auroc_out_SVHN_LB_KFAC, 'CIFAR10', 'SVHN', 'Laplace Bridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1591121503602,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "wAnbbn9KFjJm",
    "outputId": "6c4e9088-a3b4-4aa7-e16e-d79b22c0eebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Bridge time in: 0.019 with std 0.000\n",
      "Laplace Bridge time out CIFAR100: 0.018 with std 0.000\n",
      "Laplace Bridge time out notmnist: 0.046 with std 0.000\n",
      "accuracy: 0.954 with std 0.000\n",
      "MMC in: 0.966 with std 0.000\n",
      "MMC out CIFAR100: 0.741 with std 0.000\n",
      "MMC out SVHN: 0.648 with std 0.003\n",
      "AUROC out CIFAR100: 0.866 with std 0.000\n",
      "AUROC out SVHN: 0.934 with std 0.001\n"
     ]
    }
   ],
   "source": [
    "#Laplace Bridge KFAC results as presented in the main paper\n",
    "#seeds are 123,124,125,126,127\n",
    "time_lpb_in = [0.01866, 0.01882, 0.01865, 0.01834, 0.01876]\n",
    "time_lpb_out_CIFAR100 = [0.01748, 0.01794, 0.01782, 0.01756, 0.01760]\n",
    "time_lpb_out_SVHN = [0.04548, 0.04596, 0.04594, 0.04547, 0.04565]\n",
    "\n",
    "\n",
    "acc_in = [0.954, 0.954, 0.954, 0.955, 0.954]\n",
    "mmc_in = [0.966, 0.966, 0.966, 0.966, 0.966]\n",
    "mmc_out_CIFAR100 = [0.742, 0.741, 0.741, 0.742, 0.741]\n",
    "mmc_out_SVHN = [0.653, 0.645, 0.649, 0.648, 0.643]\n",
    "\n",
    "auroc_out_CIFAR100 = [0.866, 0.867, 0.866, 0.866, 0.867]\n",
    "auroc_out_SVHN = [0.932, 0.935, 0.933, 0.934, 0.936]\n",
    "\n",
    "\n",
    "print(\"Laplace Bridge time in: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_in), np.std(time_lpb_in)))\n",
    "print(\"Laplace Bridge time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_CIFAR100), np.std(time_lpb_out_CIFAR100)))\n",
    "print(\"Laplace Bridge time out notmnist: {:.03f} with std {:.03f}\".format(np.mean(time_lpb_out_SVHN), np.std(time_lpb_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVBil0N5FghP"
   },
   "source": [
    "# Conditions\n",
    "\n",
    "Test the condition derived in Proposition 1 of the paper and evaluated experimentally in Appendix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "km2YkVT7c_NU"
   },
   "outputs": [],
   "source": [
    "# check if condition holds\n",
    "\n",
    "def check_condition(alpha_vecs):\n",
    "    #note that this is vectorized\n",
    "    alpha_sum = alpha_vecs.sum(1)\n",
    "    alpha_max = alpha_vecs.max(1)\n",
    "    alpha_sum_minus = alpha_sum - alpha_max\n",
    "    right_side = 0.25 * (np.sqrt(9 * alpha_sum_minus**2 + 10 * alpha_sum_minus + 1) - alpha_sum_minus - 1)\n",
    "    cases = alpha_max > right_side\n",
    "    percentage = np.sum(cases)/len(cases)\n",
    "    return(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551468,
     "status": "ok",
     "timestamp": 1588243625471,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "hYEhWziEc_NX",
    "outputId": "658980ba-25bd-4dfa-e3e3-205d90fdc25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979\n",
      "0.9299\n",
      "0.8418100799016595\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(check_condition(CIFAR10_test_in_LB)))\n",
    "print(np.sum(check_condition(CIFAR10_test_out_CIFAR100_LB)))\n",
    "print(np.sum(check_condition(CIFAR10_test_out_SVHN_LB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551459,
     "status": "ok",
     "timestamp": 1588243625473,
     "user": {
      "displayName": "Marius Hobbhahn",
      "photoUrl": "",
      "userId": "09428085039491522481"
     },
     "user_tz": -120
    },
    "id": "R4zACU-Nm5qe",
    "outputId": "39f3877c-a17d-4cf9-fccc-7d4bfbce6ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio condition fulfilled CIFAR10 in: 0.998 with std: 0.0\n",
      "ratio condition fulfilled CIFAR100 out: 0.925 with std: 0.0\n",
      "ratio condition fulfilled SVHN out: 0.832 with std: 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "condition_CIFAR10_in = np.array([0.9977, 0.9977, 0.9977, 0.9977, 0.9977])\n",
    "condition_CIFAR100_out = np.array([0.925, 0.925, 0.925, 0.925, 0.925])\n",
    "condition_SVHN_out = np.array([0.8322833435771358, 0.8322833435771358, 0.8322833435771358, 0.8322833435771358, 0.8322833435771358])\n",
    "\n",
    "print(\"ratio condition fulfilled CIFAR10 in: {:.03f} with std: {}\".format(np.mean(condition_CIFAR10_in), np.std(condition_CIFAR10_in)))\n",
    "print(\"ratio condition fulfilled CIFAR100 out: {:.03f} with std: {}\".format(np.mean(condition_CIFAR100_out), np.std(condition_CIFAR100_out)))\n",
    "print(\"ratio condition fulfilled SVHN out: {:.03f} with std: {}\".format(np.mean(condition_SVHN_out), np.std(condition_SVHN_out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IiwWVoohRGXr"
   },
   "source": [
    "# Compare to extended MacKay approach\n",
    "\n",
    "as detailed in Appendix D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for forward pass: 0.8553376197814941\n",
      "time used for Extended MacKay Approach: 5.263708591461182\n",
      "time used for forward pass: 0.7192447185516357\n",
      "time used for Extended MacKay Approach: 3.7200324535369873\n",
      "time used for forward pass: 1.9256739616394043\n",
      "time used for Extended MacKay Approach: 9.614293813705444\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_EMK = predict_extended_MacKay(CIFAR10_model, CIFAR10_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, verbose=False, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_EMK = predict_extended_MacKay(CIFAR10_model, CIFAR100_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_EMK = predict_extended_MacKay(CIFAR10_model, SVHN_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_EMK, prob_correct_in_EMK, ent_in_EMK, MMC_in_EMK = get_in_dist_values(CIFAR10_test_in_EMK, targets_CIFAR10)\n",
    "acc_out_CIFAR100_EMK, prob_correct_out_CIFAR100_EMK, ent_out_CIFAR100_EMK, MMC_out_CIFAR100_EMK, auroc_out_CIFAR100_EMK = get_out_dist_values(CIFAR10_test_in_EMK, CIFAR10_test_out_CIFAR100_EMK, targets_CIFAR100)\n",
    "acc_out_SVHN_EMK, prob_correct_out_SVHN_EMK, ent_out_SVHN_EMK, MMC_out_SVHN_EMK, auroc_out_SVHN_EMK = get_out_dist_values(CIFAR10_test_in_EMK, CIFAR10_test_out_SVHN_EMK, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, Extended MacKay, CIFAR10] Accuracy: 0.954; average entropy: 0.081;     MMC: 0.975; Prob @ correct: 0.100\n",
      "[Out-CIFAR100, Extended MacKay, CIFAR10] Accuracy: 0.009; Average entropy: 0.581;    MMC: 0.801; AUROC: 0.880; Prob @ correct: 0.100\n",
      "[Out-SVHN, Extended MacKay, CIFAR10] Accuracy: 0.092; Average entropy: 0.771;    MMC: 0.744; AUROC: 0.929; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_EMK, prob_correct_in_EMK, ent_in_EMK, MMC_in_EMK, 'CIFAR10', 'Extended MacKay')\n",
    "print_out_dist_values(acc_out_CIFAR100_EMK, prob_correct_out_CIFAR100_EMK, ent_out_CIFAR100_EMK, MMC_out_CIFAR100_EMK, auroc_out_CIFAR100_EMK, 'CIFAR10', 'CIFAR100', 'Extended MacKay')\n",
    "print_out_dist_values(acc_out_SVHN_EMK, prob_correct_out_SVHN_EMK, ent_out_SVHN_EMK, MMC_out_SVHN_EMK, auroc_out_SVHN_EMK, 'CIFAR10', 'SVHN', 'Extended MacKay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended MacKay approach time in: 1.479 with std 0.010\n",
      "Extended MacKay approach time out CIFAR100: 1.501 with std 0.051\n",
      "Extended MacKay approach time out notmnist: 3.829 with std 0.049\n",
      "accuracy: 0.944 with std 0.001\n",
      "MMC in: 0.970 with std 0.001\n",
      "MMC out CIFAR100: 0.801 with std 0.003\n",
      "MMC out SVHN: 0.714 with std 0.036\n",
      "AUROC out CIFAR100: 0.873 with std 0.002\n",
      "AUROC out SVHN: 0.933 with std 0.012\n"
     ]
    }
   ],
   "source": [
    "#Extended MacKay approach as presented in Appendix D\n",
    "#seeds are 123,124,125,126,127\n",
    "time_emk_in = [1.4817545413970947, 1.4886608123779297, 1.482903242111206, 1.4811437129974365, 1.4604389667510986]\n",
    "time_emk_out_CIFAR100 = [1.5755081176757812, 1.4701554775238037, 1.547466516494751, 1.450073003768921, 1.461724042892456]\n",
    "time_emk_out_SVHN = [3.8533170223236084, 3.8127734661102295, 3.8204636573791504, 3.7547571659088135, 3.902277708053589]\n",
    "\n",
    "\n",
    "acc_in = [0.945, 0.945, 0.942, 0.945, 0.942]\n",
    "mmc_in = [0.972, 0.971, 0.970, 0.970, 0.969]\n",
    "mmc_out_CIFAR100 = [0.803, 0.805, 0.798, 0.797, 0.801]\n",
    "mmc_out_SVHN = [0.778, 0.679, 0.726, 0.680, 0.709]\n",
    "\n",
    "auroc_out_CIFAR100 = [0.876, 0.872, 0.873, 0.874, 0.870]\n",
    "auroc_out_SVHN = [0.918, 0.950, 0.922, 0.939, 0.935]\n",
    "\n",
    "\n",
    "print(\"Extended MacKay approach time in: {:.03f} with std {:.03f}\".format(np.mean(time_emk_in), np.std(time_emk_in)))\n",
    "print(\"Extended MacKay approach time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_emk_out_CIFAR100), np.std(time_emk_out_CIFAR100)))\n",
    "print(\"Extended MacKay approach time out notmnist: {:.03f} with std {:.03f}\".format(np.mean(time_emk_out_SVHN), np.std(time_emk_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to Second-order Delta Posterior Predictive\n",
    "\n",
    "as detailed in Appendix D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used for forward pass: 0.7208783626556396\n",
      "time used for Second order delta posterior predictive: 0.04456305503845215\n",
      "time used for forward pass: 0.7037391662597656\n",
      "time used for Second order delta posterior predictive: 0.043274879455566406\n",
      "time used for forward pass: 1.9783968925476074\n",
      "time used for Second order delta posterior predictive: 0.12188029289245605\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_test_in_SODPP = predict_SODPP(CIFAR10_model, CIFAR10_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, verbose=False, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_CIFAR100_SODPP = predict_SODPP(CIFAR10_model, CIFAR100_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, timing=True).cpu().numpy()\n",
    "CIFAR10_test_out_SVHN_SODPP = predict_SODPP(CIFAR10_model, SVHN_test_loader, M_W_post_D, M_b_post_D, C_W_post_D, C_b_post_D, cuda=cuda_status, timing=True).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_in_SODPP, prob_correct_in_SODPP, ent_in_SODPP, MMC_in_SODPP = get_in_dist_values(CIFAR10_test_in_SODPP, targets_CIFAR10)\n",
    "acc_out_CIFAR100_SODPP, prob_correct_out_CIFAR100_SODPP, ent_out_CIFAR100_SODPP, MMC_out_CIFAR100_SODPP, auroc_out_CIFAR100_SODPP = get_out_dist_values(CIFAR10_test_in_SODPP, CIFAR10_test_out_CIFAR100_SODPP, targets_CIFAR100)\n",
    "acc_out_SVHN_SODPP, prob_correct_out_SVHN_SODPP, ent_out_SVHN_SODPP, MMC_out_SVHN_SODPP, auroc_out_SVHN_SODPP = get_out_dist_values(CIFAR10_test_in_SODPP, CIFAR10_test_out_SVHN_SODPP, targets_SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[In, SODPP, CIFAR10] Accuracy: 0.954; average entropy: 0.080;     MMC: 0.975; Prob @ correct: 0.100\n",
      "[Out-CIFAR100, SODPP, CIFAR10] Accuracy: 0.009; Average entropy: 0.581;    MMC: 0.797; AUROC: 0.879; Prob @ correct: 0.100\n",
      "[Out-SVHN, SODPP, CIFAR10] Accuracy: 0.092; Average entropy: 0.771;    MMC: 0.741; AUROC: 0.928; Prob @ correct: 0.100\n"
     ]
    }
   ],
   "source": [
    "print_in_dist_values(acc_in_SODPP, prob_correct_in_SODPP, ent_in_SODPP, MMC_in_SODPP, 'CIFAR10', 'SODPP')\n",
    "print_out_dist_values(acc_out_CIFAR100_SODPP, prob_correct_out_CIFAR100_SODPP, ent_out_CIFAR100_SODPP, MMC_out_CIFAR100_SODPP, auroc_out_CIFAR100_SODPP, 'CIFAR10', 'CIFAR100', 'SODPP')\n",
    "print_out_dist_values(acc_out_SVHN_SODPP, prob_correct_out_SVHN_SODPP, ent_out_SVHN_SODPP, MMC_out_SVHN_SODPP, auroc_out_SVHN_SODPP, 'CIFAR10', 'SVHN', 'SODPP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SODPP time in: 0.024 with std 0.000\n",
      "SODPP time out CIFAR100: 0.023 with std 0.000\n",
      "SODPP time out notmnist: 0.060 with std 0.002\n",
      "accuracy: 0.944 with std 0.002\n",
      "MMC in: 0.970 with std 0.001\n",
      "MMC out CIFAR100: 0.793 with std 0.010\n",
      "MMC out SVHN: 0.710 with std 0.036\n",
      "AUROC out CIFAR100: 0.872 with std 0.002\n",
      "AUROC out SVHN: 0.932 with std 0.012\n"
     ]
    }
   ],
   "source": [
    "#Second order delta posterior predictive as shown in Appendix D\n",
    "#seeds are 123,124,125,126,127\n",
    "time_sodpp_in = [0.024459123611450195, 0.02369832992553711, 0.024019241333007812, 0.023904085159301758, 0.024046659469604492]\n",
    "time_sodpp_out_CIFAR100 = [0.023726463317871094, 0.02320384979248047, 0.023495197296142578, 0.02364373207092285, 0.022989273071289062]\n",
    "time_sodpp_out_SVHN = [0.06233024597167969, 0.058495283126831055, 0.06014561653137207, 0.061838626861572266, 0.05889773368835449]\n",
    "\n",
    "\n",
    "acc_in = [0.945, 0.946, 0.942, 0.945, 0.942]\n",
    "mmc_in = [0.971, 0.971, 0.969, 0.969, 0.969]\n",
    "mmc_out_CIFAR100 = [0.799, 0.801, 0.794, 0.773, 0.797]\n",
    "mmc_out_SVHN = [0.773, 0.675, 0.722, 0.676, 0.705]\n",
    "\n",
    "auroc_out_CIFAR100 = [0.875, 0.871, 0.872, 0.873, 0.870]\n",
    "auroc_out_SVHN = [0.917, 0.949, 0.921, 0.939, 0.935]\n",
    "\n",
    "\n",
    "print(\"SODPP time in: {:.03f} with std {:.03f}\".format(np.mean(time_sodpp_in), np.std(time_sodpp_in)))\n",
    "print(\"SODPP time out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(time_sodpp_out_CIFAR100), np.std(time_sodpp_out_CIFAR100)))\n",
    "print(\"SODPP time out notmnist: {:.03f} with std {:.03f}\".format(np.mean(time_sodpp_out_SVHN), np.std(time_sodpp_out_SVHN)))\n",
    "\n",
    "print(\"accuracy: {:.03f} with std {:.03f}\".format(np.mean(acc_in), np.std(acc_in)))\n",
    "\n",
    "print(\"MMC in: {:.03f} with std {:.03f}\".format(np.mean(mmc_in), np.std(mmc_in)))\n",
    "print(\"MMC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_CIFAR100), np.std(mmc_out_CIFAR100)))\n",
    "print(\"MMC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(mmc_out_SVHN), np.std(mmc_out_SVHN)))\n",
    "\n",
    "print(\"AUROC out CIFAR100: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_CIFAR100), np.std(auroc_out_CIFAR100)))\n",
    "print(\"AUROC out SVHN: {:.03f} with std {:.03f}\".format(np.mean(auroc_out_SVHN), np.std(auroc_out_SVHN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "BdICbIMYc_LJ",
    "UqikIW_Cc_Lb",
    "ZZj9IvJOc_MX",
    "wl2O4llSc_M1"
   ],
   "name": "Exp2_LPA_resnet_CIFAR10.ipynb",
   "provenance": [
    {
     "file_id": "1VhkPnCiC-FaV53c7VpDH44oeUMhNIIfy",
     "timestamp": 1587034936292
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
